{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e516998-1434-45f9-aa56-5c1b7a2cae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets, interact\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d1598c-2953-4119-a1ef-dded2dd829a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c063ab3291234a3f86b1525198c10b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Granularity', options=('Upto Top and Bottom Facer', 'Upto Dimensio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.handle_granularity_change(granularity_choice_value)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "# Load your dataset (example path provided, adjust as needed)\n",
    "data = pd.read_excel('Data Analysis Automation - Polyiso 2024.xlsx', sheet_name='Data set')\n",
    "\n",
    "# Check if 'DESCRIPTION' column exists\n",
    "if 'DESCRIPTION' not in data.columns:\n",
    "    raise KeyError(\"The column 'DESCRIPTION' does not exist in the dataset.\")\n",
    "\n",
    "# Global variables to hold the updated and final DataFrames\n",
    "updated_data = data.copy()\n",
    "final_df_global = None\n",
    "new_df = None  # Variable to hold the DataFrame after target column selection\n",
    "granularity_choice = 'Upto Top and Bottom Facer'  # Default value, can be changed by user\n",
    "\n",
    "# Function to convert columns to numeric with exceptions\n",
    "def convert_columns_to_numeric(df, exceptions=[]):\n",
    "    for col in df.columns:\n",
    "        if col not in exceptions:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Specify the columns to exclude from conversion\n",
    "exceptions = ['DESCRIPTION', 'SURFACTANT', 'SAP']\n",
    "\n",
    "# Convert columns to numeric with exceptions\n",
    "data = convert_columns_to_numeric(data, exceptions=exceptions)\n",
    "\n",
    "# Initialize 'SAP-Desc' and 'Merge-Key' columns if they don't exist\n",
    "if 'SAP-Desc' not in updated_data.columns:\n",
    "    updated_data['SAP-Desc'] = updated_data['DESCRIPTION']\n",
    "if 'Merge-Key' not in updated_data.columns:\n",
    "    updated_data['Merge-Key'] = np.nan\n",
    "\n",
    "def filter_dataframe(selected_values):\n",
    "    # Filter the DataFrame based on the selected values\n",
    "    filtered_df = updated_data[updated_data['DESCRIPTION'].isin(selected_values)]\n",
    "    display(filtered_df)\n",
    "    return filtered_df\n",
    "\n",
    "def select_columns(filtered_df, selected_columns):\n",
    "    final_df = filtered_df[list(selected_columns)]\n",
    "    display(final_df)\n",
    "    return final_df\n",
    "\n",
    "def create_column_dropdown(filtered_df):\n",
    "    column_options = filtered_df.columns.tolist()\n",
    "    column_dropdown = widgets.SelectMultiple(\n",
    "        options=column_options,\n",
    "        value=[column_options[0]],\n",
    "        description='Columns',\n",
    "        disabled=False\n",
    "    )\n",
    "    return column_dropdown\n",
    "\n",
    "def set_target_column(final_df, selected_column):\n",
    "    global final_df_global\n",
    "    \n",
    "    # Make a copy of the final_df to avoid modifying the original DataFrame\n",
    "    df_modified = final_df.copy()\n",
    "    \n",
    "    # Rename the selected column to 'GROUP'\n",
    "    df_modified.rename(columns={selected_column: 'GROUP'}, inplace=True)\n",
    "    \n",
    "    # Move the 'GROUP' column to the last position\n",
    "    cols = list(df_modified.columns)\n",
    "    cols.append(cols.pop(cols.index('GROUP')))\n",
    "    df_modified = df_modified[cols]\n",
    "    \n",
    "    # Convert all columns except 'SAP-Desc' or 'DESCRIPTION', 'GROUP', and 'Attributes' to numeric\n",
    "    columns_to_exclude = ['SAP-Desc', 'DESCRIPTION', 'GROUP', 'Attributes']\n",
    "    for col in df_modified.columns:\n",
    "        if col not in columns_to_exclude:\n",
    "            df_modified[col] = pd.to_numeric(df_modified[col], errors='coerce')\n",
    "    \n",
    "    # Update the global final_df_global\n",
    "    final_df_global = df_modified\n",
    "\n",
    "    # Display the modified DataFrame\n",
    "    display(final_df_global)\n",
    "    \n",
    "    return final_df_global\n",
    "\n",
    "def interactive_filter_and_select():\n",
    "    global final_df_global\n",
    "    result = {'filtered_df': None, 'final_df': None}\n",
    "\n",
    "    def update_filtered_df(selected_values):\n",
    "        filtered_df = filter_dataframe(selected_values)\n",
    "        result['filtered_df'] = filtered_df\n",
    "\n",
    "        # Create column selection dropdown after filtering\n",
    "        column_dropdown = create_column_dropdown(filtered_df)\n",
    "        display(column_dropdown)\n",
    "\n",
    "        def update_final_df(selected_columns):\n",
    "            final_df = select_columns(filtered_df, selected_columns)\n",
    "            result['final_df'] = final_df\n",
    "            final_df_global = final_df  # Store the final DataFrame in the global variable\n",
    "\n",
    "            # Create the dropdown widget for selecting the target column\n",
    "            column_options = final_df.columns.tolist()\n",
    "            target_column_dropdown = widgets.Dropdown(\n",
    "                options=column_options,\n",
    "                value=column_options[0],\n",
    "                description='Target Column',\n",
    "                disabled=False\n",
    "            )\n",
    "\n",
    "            def interactive_update(selected_column):\n",
    "                global final_df_global, new_df\n",
    "                new_df = set_target_column(final_df, selected_column)\n",
    "                # Save the new_df for the next steps in the second code block\n",
    "                final_df_global = new_df\n",
    "\n",
    "            print(\"Choose a target column: This column will be used to set up the groups for the analysis\")\n",
    "            interact(interactive_update, selected_column=target_column_dropdown)\n",
    "\n",
    "        interact(update_final_df, selected_columns=column_dropdown)\n",
    "\n",
    "    interact(update_filtered_df, selected_values=description_dropdown)\n",
    "    return description_dropdown, result\n",
    "\n",
    "# Create a dropdown widget for granularity selection\n",
    "granularity_options = ['Upto Top and Bottom Facer', 'Upto Dimensions']\n",
    "granularity_dropdown = widgets.Dropdown(\n",
    "    options=granularity_options,\n",
    "    value=granularity_options[0],\n",
    "    description='Granularity',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create a dropdown widget for DESCRIPTION selection\n",
    "description_options = data['DESCRIPTION'].unique().tolist()\n",
    "description_dropdown = widgets.SelectMultiple(\n",
    "    options=description_options,\n",
    "    value=[description_options[0]],\n",
    "    description='Description',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def handle_granularity_change(granularity_choice_value):\n",
    "    global granularity_choice\n",
    "    granularity_choice = granularity_choice_value\n",
    "\n",
    "    if granularity_choice == 'Upto Top and Bottom Facer':\n",
    "        # Proceed with the current workflow\n",
    "        dropdown_widget, result = interactive_filter_and_select()\n",
    "    else:\n",
    "        print(\"Currently, only 'Upto Top and Bottom Facer' is implemented in this block.\")\n",
    "\n",
    "interact(handle_granularity_change, granularity_choice_value=granularity_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e09a431-71bc-46e5-8ab1-4f2d0b84acde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Detected Outliers DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Column</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps</td>\n",
       "      <td>123.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps</td>\n",
       "      <td>90.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Attributes       Column  Outlier\n",
       "0  0.5 High Density Cgf-Cgf        Comps   123.21\n",
       "1  0.5 High Density Cgf-Cgf        Comps    90.35\n",
       "2          2.6 Flat Blk-Blk  EdgeCol_Top     0.26\n",
       "3          2.6 Flat Blk-Blk     W_Shrink     0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Detected Outliers DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Column</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps</td>\n",
       "      <td>123.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps</td>\n",
       "      <td>90.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Attributes       Column  Outlier\n",
       "0  0.5 High Density Cgf-Cgf        Comps   123.21\n",
       "1  0.5 High Density Cgf-Cgf        Comps    90.35\n",
       "2          2.6 Flat Blk-Blk  EdgeCol_Top     0.26\n",
       "3          2.6 Flat Blk-Blk     W_Shrink     0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove the outlier 123.21 from 0.5 High Density Cgf-Cgf in column Comps? (Yes/No):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 123.21 from 0.5 High Density Cgf-Cgf in column Comps not removed.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove the outlier 90.35 from 0.5 High Density Cgf-Cgf in column Comps? (Yes/No):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 90.35 from 0.5 High Density Cgf-Cgf in column Comps not removed.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove the outlier 0.26 from 2.6 Flat Blk-Blk in column EdgeCol_Top? (Yes/No):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 0.26 from 2.6 Flat Blk-Blk in column EdgeCol_Top not removed.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove the outlier 0.0 from 2.6 Flat Blk-Blk in column W_Shrink? (Yes/No):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 0.0 from 2.6 Flat Blk-Blk in column W_Shrink not removed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Statistics DataFrame:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>N*</th>\n",
       "      <th>Mean</th>\n",
       "      <th>StDev</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Median</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>107.776</td>\n",
       "      <td>4.468</td>\n",
       "      <td>98.580</td>\n",
       "      <td>107.380</td>\n",
       "      <td>123.210</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Comps</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>103.087</td>\n",
       "      <td>3.754</td>\n",
       "      <td>90.350</td>\n",
       "      <td>103.315</td>\n",
       "      <td>110.640</td>\n",
       "      <td>-0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>104.908</td>\n",
       "      <td>6.349</td>\n",
       "      <td>90.600</td>\n",
       "      <td>103.770</td>\n",
       "      <td>122.070</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>101.942</td>\n",
       "      <td>7.876</td>\n",
       "      <td>81.960</td>\n",
       "      <td>102.790</td>\n",
       "      <td>115.890</td>\n",
       "      <td>-0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>107.266</td>\n",
       "      <td>7.881</td>\n",
       "      <td>88.610</td>\n",
       "      <td>107.435</td>\n",
       "      <td>125.840</td>\n",
       "      <td>-0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Attributes    GROUP        Variable   N  N*     Mean  StDev  \\\n",
       "0   0.5 High Density Cgf-Cgf   EVONIK           Comps  64   0  107.776  4.468   \n",
       "1   0.5 High Density Cgf-Cgf  SILSTAB           Comps  38   0  103.087  3.754   \n",
       "2   0.5 High Density Cgf-Cgf   EVONIK     Comps_Thick  64   0  104.908  6.349   \n",
       "3   0.5 High Density Cgf-Cgf  SILSTAB     Comps_Thick  38   0  101.942  7.876   \n",
       "4   0.5 High Density Cgf-Cgf   EVONIK      Comps_Thin  64   0  107.266  7.881   \n",
       "..                       ...      ...             ...  ..  ..      ...    ...   \n",
       "75           Q Taper Blk-Blk  SILSTAB  Kfactor_Init-1  18   0    0.000  0.000   \n",
       "76           Q Taper Blk-Blk   EVONIK        L_Shrink  23   0    0.000  0.000   \n",
       "77           Q Taper Blk-Blk  SILSTAB        L_Shrink  18   0    0.000  0.000   \n",
       "78           Q Taper Blk-Blk   EVONIK        W_Shrink  23   0    0.000  0.000   \n",
       "79           Q Taper Blk-Blk  SILSTAB        W_Shrink  18   0    0.000  0.000   \n",
       "\n",
       "   Minimum   Median  Maximum Skewness  \n",
       "0   98.580  107.380  123.210    0.679  \n",
       "1   90.350  103.315  110.640   -0.915  \n",
       "2   90.600  103.770  122.070    0.414  \n",
       "3   81.960  102.790  115.890   -0.450  \n",
       "4   88.610  107.435  125.840   -0.098  \n",
       "..     ...      ...      ...      ...  \n",
       "75   0.000    0.000    0.000    0.000  \n",
       "76   0.000    0.000    0.000    0.000  \n",
       "77   0.000    0.000    0.000    0.000  \n",
       "78   0.000    0.000    0.000    0.000  \n",
       "79   0.000    0.000    0.000    0.000  \n",
       "\n",
       "[80 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from scipy import stats\n",
    "\n",
    "outliers_df_global = pd.DataFrame(columns=['Attributes', 'Column', 'Outlier'])\n",
    "\n",
    "def extract_attributes(description, granularity_choice):\n",
    "    if granularity_choice == 'Upto Dimensions':\n",
    "        parts = description.split(\" \")\n",
    "        attributes = \" \".join(parts[:-2]) + \"-\" + parts[-2] + \" \" + parts[-1]\n",
    "        return attributes\n",
    "    else:\n",
    "        match = re.match(r\"(\\d+\\.\\d+|\\d+|\\b[a-zA-Z]\\b)\\s+(.+?)\\s+\\d\", description)\n",
    "        if match:\n",
    "            thickness = match.group(1)\n",
    "            material_type = match.group(2)\n",
    "            return f\"{thickness} {material_type}\"\n",
    "        return None\n",
    "\n",
    "def grubbs_test(data, alpha=0.05):\n",
    "    n = len(data)\n",
    "    if n < 3:  # Grubbs' test requires at least 3 data points\n",
    "        return None, None\n",
    "    mean_y = np.mean(data)\n",
    "    std_y = np.std(data, ddof=1)\n",
    "    if std_y == 0:\n",
    "        return None, None\n",
    "    numerator = np.max(np.abs(data - mean_y))\n",
    "    grubbs_statistic = numerator / std_y\n",
    "    \n",
    "    t_dist = stats.t.ppf(1 - alpha / (2 * n), n - 2)\n",
    "    critical_value = ((n - 1) / np.sqrt(n)) * np.sqrt(t_dist ** 2 / (n - 2 + t_dist ** 2))\n",
    "    \n",
    "    return grubbs_statistic, critical_value\n",
    "\n",
    "def detect_outliers(final_df, granularity_choice, alpha=0.05):\n",
    "    global outliers_df_global\n",
    "\n",
    "    # Determine the appropriate column to use based on granularity choice\n",
    "    if granularity_choice == 'Upto Top and Bottom Facer':\n",
    "        column_to_use = 'DESCRIPTION'\n",
    "    else:\n",
    "        column_to_use = 'SAP-Desc'\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid SettingWithCopyWarning\n",
    "    final_df = final_df.copy()\n",
    "\n",
    "    final_df['Attributes'] = final_df[column_to_use].apply(lambda x: extract_attributes(x, granularity_choice))\n",
    "\n",
    "    # List to capture outliers\n",
    "    outliers_list = []\n",
    "\n",
    "    grouped = final_df.groupby('Attributes')\n",
    "    for attr, group_df in grouped:\n",
    "        for column in group_df.columns:\n",
    "            if group_df[column].dtype != object and column != 'GROUP':  # Ensure the column is numeric\n",
    "                data_column = pd.to_numeric(group_df[column], errors='coerce').dropna().values\n",
    "                while True:\n",
    "                    grubbs_statistic, critical_value = grubbs_test(data_column, alpha)\n",
    "                    if grubbs_statistic is None or critical_value is None:\n",
    "                        break\n",
    "                    if grubbs_statistic > critical_value:\n",
    "                        outlier = data_column[np.argmax(np.abs(data_column - np.mean(data_column)))]\n",
    "                        outliers_list.append({'Attributes': attr, 'Column': column, 'Outlier': outlier})\n",
    "                        data_column = data_column[data_column != outlier]\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "    outliers_df_global = pd.DataFrame(outliers_list)\n",
    "\n",
    "    # Display the detected outliers DataFrame\n",
    "    display(HTML(\"<b>Detected Outliers DataFrame:</b>\"))\n",
    "    display(outliers_df_global)\n",
    "\n",
    "def add_attributes_column(final_df, granularity_choice):\n",
    "    if granularity_choice == 'Upto Top and Bottom Facer':\n",
    "        final_df['Attributes'] = final_df['DESCRIPTION'].apply(lambda x: extract_attributes(x, granularity_choice))\n",
    "    else:\n",
    "        final_df['Attributes'] = final_df['SAP-Desc'].apply(lambda x: extract_attributes(x, granularity_choice))\n",
    "    return final_df\n",
    "\n",
    "def prompt_outlier_removal(final_df, outliers_df, granularity_choice):\n",
    "    # Add the 'Attributes' column to the DataFrame\n",
    "    final_df = add_attributes_column(final_df, granularity_choice)\n",
    "\n",
    "    # Display the detected outliers DataFrame\n",
    "    display(HTML(\"<b>Detected Outliers DataFrame:</b>\"))\n",
    "    display(outliers_df)\n",
    "    \n",
    "    # If no outliers are detected, print a message and return\n",
    "    if outliers_df.empty:\n",
    "        print(\"No outliers detected.\")\n",
    "        return final_df\n",
    "    \n",
    "    # Iterate over each outlier and ask the user whether to remove it\n",
    "    for index, row in outliers_df.iterrows():\n",
    "        attr = row['Attributes']\n",
    "        column = row['Column']\n",
    "        outlier_value = row['Outlier']\n",
    "        \n",
    "        # Ask the user for a decision\n",
    "        decision = input(f\"Do you want to remove the outlier {outlier_value} from {attr} in column {column}? (Yes/No): \").strip().lower()\n",
    "        \n",
    "        if decision == 'yes':\n",
    "            final_df = final_df[~((final_df[column] == outlier_value) & (final_df['Attributes'] == attr))]\n",
    "            print(f\"Outlier {outlier_value} from {attr} in column {column} removed.\")\n",
    "        else:\n",
    "            print(f\"Outlier {outlier_value} from {attr} in column {column} not removed.\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def calculate_statistics(df, description_column, group_column, granularity_choice):\n",
    "    df['Attributes'] = df[description_column].apply(lambda x: extract_attributes(x, granularity_choice))\n",
    "    \n",
    "    # Drop rows where attributes could not be extracted\n",
    "    df = df.dropna(subset=['Attributes'])\n",
    "    \n",
    "    # Group by the extracted attributes and the specified group column\n",
    "    grouped = df.groupby(['Attributes', group_column])\n",
    "    \n",
    "    def group_stats(group):\n",
    "        group = group.drop(columns=[description_column, 'Attributes', group_column])\n",
    "        stats = {\n",
    "            'N': group.shape[0],\n",
    "            'N*': group.isnull().sum(),\n",
    "            'Mean': group.mean(numeric_only=True),\n",
    "            'StDev': group.std(numeric_only=True),\n",
    "            'Minimum': group.min(numeric_only=True),\n",
    "            'Median': group.median(numeric_only=True),\n",
    "            'Maximum': group.max(numeric_only=True),\n",
    "            'Skewness': group.skew(numeric_only=True)\n",
    "        }\n",
    "        return pd.DataFrame(stats)\n",
    "    \n",
    "    stats_df = grouped.apply(group_stats).reset_index()\n",
    "    return stats_df\n",
    "\n",
    "def calculate_and_display_statistics(final_df, granularity_choice):\n",
    "    global table1_df_global\n",
    "\n",
    "    if granularity_choice == 'Upto Top and Bottom Facer':\n",
    "        description_column = 'DESCRIPTION'\n",
    "        group_column = 'GROUP'\n",
    "    else:\n",
    "        description_column = 'SAP-Desc'\n",
    "        group_column = 'GROUP'\n",
    "        \n",
    "    stats_df = calculate_statistics(final_df, description_column, group_column, granularity_choice)\n",
    "    stats_df.rename(columns={'level_2': 'Variable'}, inplace=True)\n",
    "\n",
    "    columns_order = ['Attributes', 'GROUP', 'Variable', 'N', 'N*', 'Mean', 'StDev', 'Minimum', 'Median', 'Maximum', 'Skewness']\n",
    "    stats_df = stats_df[columns_order].round(3)\n",
    "\n",
    "    pd.options.display.float_format = '{:.6f}'.format\n",
    "\n",
    "    for col in ['Mean', 'StDev', 'Minimum', 'Median', 'Maximum', 'Skewness']:\n",
    "        if col in stats_df.columns:\n",
    "            stats_df[col] = stats_df[col].apply(lambda x: f\"{x:.3f}\" if pd.notnull(x) else x)\n",
    "\n",
    "    table1_df = stats_df.sort_values(by=['Attributes', 'Variable', 'GROUP']).reset_index().drop(columns=['index'])\n",
    "    table1_df_global = table1_df\n",
    "\n",
    "    display(HTML(\"<b>Statistics DataFrame:</b>\"))\n",
    "    display(table1_df)\n",
    "\n",
    "# Ensure final_df_global is assigned properly in the first block\n",
    "if final_df_global is not None:\n",
    "    final_df_global = add_attributes_column(final_df_global, granularity_choice)\n",
    "    detect_outliers(final_df_global, granularity_choice, alpha=0.05)\n",
    "    final_df_global = prompt_outlier_removal(final_df_global, outliers_df_global, granularity_choice)\n",
    "    calculate_and_display_statistics(final_df_global, granularity_choice)\n",
    "else:\n",
    "    print(\"final_df_global is not yet defined. Please complete the interactive selections in the first code block.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218ce472-cdbb-4043-878d-ce08572a420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=final_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc41bd6e-7fb0-4a0d-832f-152d32bf73c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['Core', 'Comps_Thin', 'Comps_Thick', 'Comps', 'F_Thick', 'Kfactor_Init-1', 'EdgeCol_Bot', 'EdgeCol_Top', 'L_Shrink', 'W_Shrink']\n",
      "AD Test Result = No, reject null\n",
      "p<=0.05  reject null\n",
      "Group counts:\n",
      " Attributes                GROUP  \n",
      "0.5 High Density Cgf-Cgf  EVONIK     64\n",
      "                          SILSTAB    38\n",
      "1.5 Flat Blk-Blk          EVONIK     36\n",
      "                          SILSTAB    25\n",
      "2.6 Flat Blk-Blk          EVONIK     15\n",
      "                          SILSTAB    11\n",
      "Q Taper Blk-Blk           EVONIK     23\n",
      "                          SILSTAB    18\n",
      "dtype: int64\n",
      "Number of unique groups: Attributes\n",
      "0.5 High Density Cgf-Cgf    2\n",
      "1.5 Flat Blk-Blk            2\n",
      "2.6 Flat Blk-Blk            2\n",
      "Q Taper Blk-Blk             2\n",
      "dtype: int64\n",
      "Number of unique groups for 0.5 High Density Cgf-Cgf is between 2 and 9.\n",
      "All groups in 0.5 High Density Cgf-Cgf have more than 15 records.\n",
      "Number of unique groups for 1.5 Flat Blk-Blk is between 2 and 9.\n",
      "All groups in 1.5 Flat Blk-Blk have more than 15 records.\n",
      "Number of unique groups for 2.6 Flat Blk-Blk is between 2 and 9.\n",
      "At least one group in 2.6 Flat Blk-Blk has 15 or fewer records.\n",
      "Number of unique groups for Q Taper Blk-Blk is between 2 and 9.\n",
      "All groups in Q Taper Blk-Blk have more than 15 records.\n",
      "Result from Minimum Group Records Test = No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chilukalo\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf5f6f80aaa498bb00b08ea8513ca76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Choose Test:', options=('Equal Variance Test', 'Non-Parametric Tes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for column: Core\n",
      "Skipping Tukey HSD plot for Core: Axis limits cannot be NaN or Inf\n",
      "Plotting for column: Comps_Thin\n",
      "Plotting for column: Comps_Thick\n",
      "Plotting for column: Comps\n",
      "Plotting for column: F_Thick\n",
      "Plotting for column: Kfactor_Init-1\n",
      "Skipping Tukey HSD plot for Kfactor_Init-1: Axis limits cannot be NaN or Inf\n",
      "Plotting for column: EdgeCol_Bot\n",
      "Skipping Tukey HSD plot for EdgeCol_Bot: Axis limits cannot be NaN or Inf\n",
      "Plotting for column: EdgeCol_Top\n",
      "Skipping Tukey HSD plot for EdgeCol_Top: Axis limits cannot be NaN or Inf\n",
      "Plotting for column: L_Shrink\n",
      "Skipping Tukey HSD plot for L_Shrink: Axis limits cannot be NaN or Inf\n",
      "Plotting for column: W_Shrink\n",
      "Skipping Tukey HSD plot for W_Shrink: Axis limits cannot be NaN or Inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import levene, f_oneway, kruskal, median_test\n",
    "from statsmodels.stats.weightstats import CompareMeans, DescrStatsW\n",
    "from fuzzywuzzy import fuzz\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import io\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global variable to store results\n",
    "global_results = []\n",
    "global_levene_results = []\n",
    "global_anova_welch_results = []\n",
    "user_choice_2 = None  # Initialize user_choice_2\n",
    "plots_dict = {}  # Dictionary to store plots\n",
    "\n",
    "# Assuming filtered_data and table1_df are already loaded\n",
    "\n",
    "def anderson_darling_test(data):\n",
    "    data = np.asarray(data).flatten()\n",
    "    result = stats.anderson(data, dist='norm')\n",
    "    return result.statistic, result.critical_values, result.significance_level\n",
    "\n",
    "# Function to find representative description\n",
    "def find_representative_description(descriptions, threshold=80):\n",
    "    unique_descriptions = np.unique(descriptions)\n",
    "    representative_description = unique_descriptions[0]\n",
    "    for desc in unique_descriptions[1:]:\n",
    "        if fuzz.ratio(representative_description, desc) >= threshold:\n",
    "            continue\n",
    "        else:\n",
    "            representative_description = desc\n",
    "            break\n",
    "    return representative_description\n",
    "\n",
    "# Function to plot standard deviations\n",
    "def plot_standard_deviations(column, group_labels, means, std_devs, p_value_1, p_value_2):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.errorbar(means, group_labels, xerr=std_devs, fmt='o', capsize=5, capthick=2, elinewidth=2, linestyle='None')\n",
    "    ax.set_title(f'Test for Equal Variances: {column} vs GROUP\\nMultiple comparison intervals for the standard deviation, α = 0.05')\n",
    "    ax.set_ylabel('GROUP')\n",
    "    ax.set_xlabel('Standard Deviation')\n",
    "    plt.figtext(0.95, 0.9, f\"Multiple Comparisons\\nP-Value (Levene's Test)\\nP-Value: {p_value_1:.3f}\", bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5})\n",
    "    plt.figtext(0.95, 0.8, f\"P-Value (ANOVA or Welch)\\nP-Value: {p_value_2:.3f}\", bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5})\n",
    "    ax.set_yticks(range(len(group_labels)))\n",
    "    ax.set_yticklabels(group_labels)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "# Function to handle user's choice for EVT or NPT\n",
    "def handle_choice_1(choice):\n",
    "    global user_choice_1\n",
    "    user_choice_1 = choice\n",
    "    print(f\"User choice: {user_choice_1}\")\n",
    "    if user_choice_1 == 'Equal Variance Test':\n",
    "        equal_variance_test()\n",
    "    elif user_choice_1 == 'Non-Parametric Test':\n",
    "        check_extreme_outliers()\n",
    "\n",
    "# Function to handle user's choice for non-parametric test\n",
    "def handle_choice_2(attr, group_df):\n",
    "    def handle_choice_test(choice):\n",
    "        global user_choice_2, global_results\n",
    "        user_choice_2 = choice\n",
    "        print(f\"User choice for {attr}: {user_choice_2}\")\n",
    "\n",
    "        # Remove existing results for the chosen attribute and test type\n",
    "        global_results = [result for result in global_results if not (result['Attributes'] == attr and result['Test Conducted'] == user_choice_2)]\n",
    "        \n",
    "        if user_choice_2 == \"Mood's Median\":\n",
    "            results = moods_median_test(group_df, attr)\n",
    "        elif user_choice_2 == 'Kruskal-Wallis':\n",
    "            results = kruskal_wallis_test(group_df, attr)\n",
    "        \n",
    "        global_results.extend(results)\n",
    "        results_df = pd.DataFrame(results)\n",
    "        display(results_df)\n",
    "        return results\n",
    "\n",
    "    interact_widget = interact(handle_choice_test, choice=widgets.Dropdown(options=[\"Mood's Median\", 'Kruskal-Wallis'], description='Choose Test:'))\n",
    "    return interact_widget.widget.result\n",
    "\n",
    "# Function to check skewness and proceed\n",
    "def check_skewness_and_proceed():\n",
    "    table1_df_global['Skewness'] = pd.to_numeric(table1_df_global['Skewness'], errors='coerce')\n",
    "    skewness_check = table1_df_global['Skewness'].apply(lambda x: -2 <= x <= 2 if pd.notna(x) else True)\n",
    "    if skewness_check.all():\n",
    "        print(\"Skewness for all records is between -2 and 2. Proceed to user choice.\")\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "    else:\n",
    "        print(\"Skewness for some records is outside the range of -2 and 2. Suggesting Non-Parametric Test (NPT) instead.\")\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "\n",
    "# Perform Anderson-Darling Test\n",
    "def perform_anderson_darling_test():\n",
    "    numerical_columns = [col for col in filtered_data.columns if pd.api.types.is_numeric_dtype(filtered_data[col])]\n",
    "    print(f\"Numerical columns: {numerical_columns}\")\n",
    "    data_for_testing = filtered_data[numerical_columns].values.flatten()\n",
    "    statistic, critical_values, significance_level = anderson_darling_test(data_for_testing)\n",
    "    p_value_threshold = 0.05\n",
    "    if statistic < critical_values[2]:\n",
    "        result = \"Yes, fail to reject null\"\n",
    "        print(f\"AD Test Result = {result}\")\n",
    "        print(\"p>0.05  fail to reject null\")\n",
    "        check_skewness_and_proceed()\n",
    "    else:\n",
    "        result = \"No, reject null\"\n",
    "        print(f\"AD Test Result = {result}\")\n",
    "        print(\"p<=0.05  reject null\")\n",
    "        perform_mgrt_test()\n",
    "\n",
    "# Function to perform Minimum Group Records Test (MGRT)\n",
    "def perform_mgrt_test():\n",
    "    group_counts = filtered_data.groupby(['Attributes', 'GROUP']).size()\n",
    "    print(\"Group counts:\\n\", group_counts)\n",
    "    num_unique_groups = group_counts.groupby(level=0).size()\n",
    "    print(f\"Number of unique groups: {num_unique_groups}\")\n",
    "    result_MGRT = \"Yes\"\n",
    "    for attr, group_count in group_counts.groupby(level=0):\n",
    "        if 2 <= len(group_count) <= 9:\n",
    "            print(f\"Number of unique groups for {attr} is between 2 and 9.\")\n",
    "            if not all(group_count > 15):\n",
    "                result_MGRT = \"No\"\n",
    "                print(f\"At least one group in {attr} has 15 or fewer records.\")\n",
    "            else:\n",
    "                print(f\"All groups in {attr} have more than 15 records.\")\n",
    "        elif 10 <= len(group_count) <= 12:\n",
    "            print(f\"Number of unique groups for {attr} is between 10 and 12.\")\n",
    "            if not all(group_count > 20):\n",
    "                result_MGRT = \"No\"\n",
    "                print(f\"At least one group in {attr} has 20 or fewer records.\")\n",
    "            else:\n",
    "                print(f\"All groups in {attr} have more than 20 records.\")\n",
    "        else:\n",
    "            print(f\"Number of unique groups for {attr} is outside the specified range (2-12).\")\n",
    "    print(f\"Result from Minimum Group Records Test = {result_MGRT}\")\n",
    "    if result_MGRT == \"Yes\":\n",
    "        check_skewness_and_proceed()\n",
    "    else:\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "\n",
    "# Function to perform Equal Variance Test\n",
    "def equal_variance_test():\n",
    "    global global_levene_results, global_anova_welch_results\n",
    "    descriptions = filtered_data['Attributes']\n",
    "    representative_description = find_representative_description(descriptions)\n",
    "    levene_results = []\n",
    "    anova_welch_results = []\n",
    "    numeric_columns = filtered_data.select_dtypes(include='number').columns\n",
    "    grouped = filtered_data.groupby('Attributes')\n",
    "    for attr, group_df in grouped:\n",
    "        print(f\"Processing group: Attributes={attr}\")\n",
    "        for column in numeric_columns:\n",
    "            if column != 'GROUP':\n",
    "                groups = group_df.groupby('GROUP')[column].apply(lambda x: x.dropna().values)\n",
    "                group_labels = [label for label, group in zip(groups.index, groups) if len(group) > 0]\n",
    "                means = [np.mean(group) for group in groups if len(group) > 0]\n",
    "                std_devs = [np.std(group) for group in groups if len(group) > 0]\n",
    "                if not means or not std_devs:\n",
    "                    continue\n",
    "                print(f\"\\nTesting column: {column}\")\n",
    "                for label, group in zip(group_labels, groups):\n",
    "                    print(f\"Group: {label}, Data: {group}\")\n",
    "                try:\n",
    "                    stat, p_value_1 = levene(*[group for group in groups if len(group) > 0])\n",
    "                    if np.isnan(p_value_1):\n",
    "                        raise ValueError(\"NaN P-Value\")\n",
    "                except:\n",
    "                    p_value_1 = np.nan\n",
    "                    levene_results.append({\n",
    "                        'Column': column,\n",
    "                        'Levene P-Value': 'N/A',\n",
    "                        'Result': 'N/A',\n",
    "                        'Attributes': attr\n",
    "                    })\n",
    "                    anova_welch_results.append({\n",
    "                        'Column': column,\n",
    "                        'ANOVA/Welch P-Value': 'N/A',\n",
    "                        'Result': 'N/A',\n",
    "                        'Test Type': 'N/A',\n",
    "                        'Attributes': attr\n",
    "                    })\n",
    "                    continue\n",
    "                levene_result = 'Equal' if p_value_1 > 0.05 else 'Diff'\n",
    "                levene_results.append({\n",
    "                    'Column': column,\n",
    "                    'Levene P-Value': p_value_1,\n",
    "                    'Levene Statistic': stat,\n",
    "                    'Result': levene_result,\n",
    "                    'Attributes': attr\n",
    "                })\n",
    "                try:\n",
    "                    if p_value_1 > 0.05:\n",
    "                        print(f\"Yes, Parametric ANOVA for {column}\")\n",
    "                        anova_result = f_oneway(*[group for group in groups if len(group) > 0])\n",
    "                        p_value_2 = anova_result.pvalue\n",
    "                        if np.isnan(p_value_2):\n",
    "                            raise ValueError(\"NaN P-Value\")\n",
    "                        if p_value_2 > 0.05:\n",
    "                            result = 'Equal'\n",
    "                            test_type = 'ANOVA'\n",
    "                        else:\n",
    "                            result = 'Diff'\n",
    "                            test_type = 'ANOVA'\n",
    "                    else:\n",
    "                        print(f\"No, Parametric Welch ANOVA for {column}\")\n",
    "                        desc_stats = [DescrStatsW(group) for group in groups if len(group) > 0]\n",
    "                        cm = CompareMeans(*desc_stats)\n",
    "                        welch_result = cm.ttest_ind(usevar='unequal')\n",
    "                        p_value_2 = welch_result[1]\n",
    "                        if np.isnan(p_value_2):\n",
    "                            raise ValueError(\"NaN P-Value\")\n",
    "                        if p_value_2 > 0.05:\n",
    "                            result = 'Equal'\n",
    "                            test_type = 'Welch ANOVA'\n",
    "                        else:\n",
    "                            result = 'Diff'\n",
    "                            test_type = 'Welch ANOVA'\n",
    "                except:\n",
    "                    p_value_2 = np.nan\n",
    "                    result = 'N/A'\n",
    "                    test_type = 'N/A'\n",
    "                fig = plot_standard_deviations(column, group_labels, means, std_devs, p_value_1, p_value_2)\n",
    "                plots_dict.setdefault('standard_deviations', []).append((f'{attr}_{column}', fig))\n",
    "                anova_welch_results.append({\n",
    "                    'Column': column,\n",
    "                    'ANOVA/Welch P-Value': p_value_2,\n",
    "                    'Result': result,\n",
    "                    'Test Type': test_type,\n",
    "                    'Attributes': attr\n",
    "                })\n",
    "    global_levene_results = pd.DataFrame(levene_results)\n",
    "    global_anova_welch_results = pd.DataFrame(anova_welch_results)\n",
    "    # Format the DataFrames as requested\n",
    "    levene_df_pivot = pd.pivot_table(global_levene_results, index='Attributes', columns='Column', values='Levene P-Value', aggfunc='first')\n",
    "    anova_welch_df_pivot = pd.pivot_table(global_anova_welch_results, index='Attributes', columns='Column', values='ANOVA/Welch P-Value', aggfunc='first')\n",
    "    # DataFrames without p-values\n",
    "    levene_df_simple = global_levene_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "    anova_welch_df_simple = global_anova_welch_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "    print(\"Levene's Test Results (with P-Values):\")\n",
    "    display(levene_df_pivot)\n",
    "    print(\"\\nANOVA/Welch Test Results (with P-Values):\")\n",
    "    display(anova_welch_df_pivot)\n",
    "    print(\"\\nLevene's Test Results (Simplified):\")\n",
    "    display(levene_df_simple)\n",
    "    print(\"\\nANOVA/Welch Test Results (Simplified):\")\n",
    "    display(anova_welch_df_simple)\n",
    "\n",
    "# Function to perform Mood's Median Test\n",
    "def moods_median_test(group_df, attr):\n",
    "    numeric_columns = group_df.select_dtypes(include='number').columns\n",
    "    results = []\n",
    "    for column in numeric_columns:\n",
    "        if column != 'GROUP':\n",
    "            groups = [group[column].dropna().values for name, group in group_df.groupby('GROUP')]\n",
    "            groups = [group for group in groups if len(group) > 0]\n",
    "            if len(groups) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                stat, p_value, med, tbl = median_test(*groups)\n",
    "                if p_value > 0.05:\n",
    "                    result = 'Equal'\n",
    "                else:\n",
    "                    result = 'Diff'\n",
    "                group_stats = group_df.groupby('GROUP')[column].describe().unstack()\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': group_stats['50%'].to_dict(),\n",
    "                    'N': group_stats['count'].to_dict(),\n",
    "                    'Q1-Q3': group_stats[['25%', '75%']].to_dict(),\n",
    "                    'H-Value': stat,\n",
    "                    'P-Value': p_value,\n",
    "                    'Result': result,\n",
    "                    'Test Conducted': \"Mood's Median\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "            except ValueError as e:\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': np.nan,\n",
    "                    'N': len(group_df),\n",
    "                    'Q1-Q3': 'N/A',\n",
    "                    'H-Value': np.nan,\n",
    "                    'P-Value': np.nan,\n",
    "                    'Result': 'N/A',\n",
    "                    'Test Conducted': \"Mood's Median\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "    return results\n",
    "\n",
    "# Function to perform Kruskal-Wallis Test\n",
    "def kruskal_wallis_test(group_df, attr):\n",
    "    numeric_columns = group_df.select_dtypes(include='number').columns\n",
    "    results = []\n",
    "    for column in numeric_columns:\n",
    "        if column != 'GROUP':\n",
    "            groups = [group[column].dropna().values for name, group in group_df.groupby('GROUP')]\n",
    "            groups = [group for group in groups if len(group) > 0]\n",
    "            if len(groups) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                stat, p_value = kruskal(*groups)\n",
    "                if p_value > 0.05:\n",
    "                    result = 'Equal'\n",
    "                else:\n",
    "                    result = 'Diff'\n",
    "                group_stats = group_df.groupby('GROUP')[column].describe().unstack()\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': group_stats['50%'].to_dict(),\n",
    "                    'N': group_stats['count'].to_dict(),\n",
    "                    'Q1-Q3': group_stats[['25%', '75%']].to_dict(),\n",
    "                    'H-Value': stat,\n",
    "                    'P-Value': p_value,\n",
    "                    'Result': result,\n",
    "                    'Test Conducted': \"Kruskal-Wallis\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "            except ValueError as e:\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': np.nan,\n",
    "                    'N': len(group_df),\n",
    "                    'Q1-Q3': 'N/A',\n",
    "                    'H-Value': np.nan,\n",
    "                    'P-Value': np.nan,\n",
    "                    'Result': 'N/A',\n",
    "                    'Test Conducted': \"Kruskal-Wallis\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "    return results\n",
    "\n",
    "# Function to perform tests by attribute\n",
    "def perform_tests_by_attribute():\n",
    "    all_results = []\n",
    "    for attr in filtered_data['Attributes'].unique():\n",
    "        group_df = filtered_data[filtered_data['Attributes'] == attr]\n",
    "        print(f\"\\nChoose the test to conduct for {attr}:\")\n",
    "        results_df = handle_choice_2(attr, group_df)\n",
    "        if results_df is not None:  # Ensure the results are valid\n",
    "            all_results.append(results_df)\n",
    "\n",
    "    # Collect the results from each attribute\n",
    "    all_results_list = []\n",
    "    for results_df in all_results:\n",
    "        if isinstance(results_df, list):  # Check if it's a list\n",
    "            all_results_list.extend(results_df)\n",
    "\n",
    "    # Update the global results list\n",
    "    global global_results\n",
    "    global_results.extend(all_results_list)\n",
    "\n",
    "# Function to check extreme outliers\n",
    "def check_extreme_outliers():\n",
    "    def find_extreme_outliers(series):\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        mean = series.mean()\n",
    "        outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "        distances = (outliers - mean).abs()\n",
    "        return outliers, distances\n",
    "\n",
    "    outlier_present = False\n",
    "    outliers_list = []\n",
    "    numeric_columns = filtered_data.select_dtypes(include='number').columns\n",
    "    grouped = filtered_data.groupby('Attributes')\n",
    "    for attr, group_df in grouped:\n",
    "        for column in numeric_columns:\n",
    "            if column != 'GROUP':\n",
    "                valid_groups = group_df['GROUP'].dropna().unique()\n",
    "                if len(valid_groups) > 0:  # Ensure there are valid groups to plot\n",
    "                    groups = group_df.groupby('GROUP')[column].apply(lambda x: x.dropna().values)\n",
    "                    valid_groups = [group for group in groups if len(group) > 0]\n",
    "                    if len(valid_groups) < 2:\n",
    "                        continue\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.boxplot(x='GROUP', y=column, data=group_df)\n",
    "                    plt.title(f\"Boxplot of {column} by GROUP for Attributes={attr}\")\n",
    "                    plt.close()\n",
    "                    plots_dict.setdefault('boxplot', []).append((f'{attr}_{column}', plt.gcf()))\n",
    "                for name, group in group_df.groupby('GROUP'):\n",
    "                    outliers, distances = find_extreme_outliers(group[column])\n",
    "                    if not outliers.empty:\n",
    "                        outlier_present = True\n",
    "                        print(f\"Column: {column}, Group: {name}, Attributes: {attr}\")\n",
    "                        print(\"Outliers and their distances from the mean:\")\n",
    "                        for value, distance in zip(outliers, distances):\n",
    "                            print(f\"Outlier: {value}, Distance from mean: {distance}\")\n",
    "                            outliers_list.append({\n",
    "                                'Column': column,\n",
    "                                'Group': name,\n",
    "                                'Attributes': attr,\n",
    "                                'Outlier': value,\n",
    "                                'Distance from Mean': distance\n",
    "                            })\n",
    "    result = \"Yes\" if outlier_present else \"No\"\n",
    "    print(f\"Extreme outliers present: {result}\")\n",
    "    outliers_df = pd.DataFrame(outliers_list)\n",
    "    display(outliers_df)\n",
    "    perform_tests_by_attribute()\n",
    "\n",
    "# Plotting functions for visualization\n",
    "def plot_tukey_CIs(data, group_col, value_col):\n",
    "    try:\n",
    "        from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "        tukey_result = pairwise_tukeyhsd(endog=data[value_col], groups=data[group_col], alpha=0.05)\n",
    "        tukey_result.plot_simultaneous()\n",
    "        plt.title(f'Tukey Simultaneous 95% CIs\\nDifferences of Means for {value_col}')\n",
    "        plt.xlabel('Difference of Means')\n",
    "        plt.grid()\n",
    "        plt.close()\n",
    "        return plt.gcf()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping Tukey HSD plot for {value_col}: {e}\")\n",
    "        return None\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_interval(data, group_col, value_col):\n",
    "    # Plot points without the join parameter\n",
    "    sns.pointplot(x=group_col, y=value_col, data=data, capsize=.1, errwidth=1.5, errorbar='sd')\n",
    "    \n",
    "    # Add a line plot to connect the points\n",
    "    plt.plot(data[group_col], data[value_col], linestyle='-', color='red')\n",
    "    \n",
    "    plt.title(f'Interval Plot of {value_col} vs {group_col}\\n95% CI for the Mean')\n",
    "    plt.ylabel(value_col)\n",
    "    plt.xlabel(group_col)\n",
    "    plt.grid()\n",
    "    plt.close()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def plot_individual_value(data, group_col, value_col):\n",
    "    # Plot individual points using stripplot with jitter for better visualization\n",
    "    sns.stripplot(x=group_col, y=value_col, data=data, jitter=True)\n",
    "    \n",
    "    # Plot point estimates and error bars\n",
    "    sns.pointplot(x=group_col, y=value_col, data=data, errorbar='sd', color='red')\n",
    "    \n",
    "    # Manually add lines if you want to connect the points\n",
    "    plt.plot(data[group_col], data.groupby(group_col)[value_col].mean(), linestyle='-', color='red')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title(f'Individual Value Plot of {value_col} vs {group_col}')\n",
    "    plt.ylabel(value_col)\n",
    "    plt.xlabel(group_col)\n",
    "    \n",
    "    # Add a grid for better readability\n",
    "    plt.grid()\n",
    "    \n",
    "    # Close the plot to avoid displaying in non-interactive environments\n",
    "    plt.close()\n",
    "    \n",
    "    # Return the current figure object\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_boxplot(data, group_col, value_col):\n",
    "    # Drop rows with NaN values in the group or value columns\n",
    "    data = data.dropna(subset=[group_col, value_col])\n",
    "    \n",
    "    # Check if there are at least two groups with data\n",
    "    if data[group_col].nunique() < 2:\n",
    "        print(f\"Not enough groups to plot boxplot for {value_col}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Plot the boxplot\n",
    "        sns.boxplot(x=group_col, y=value_col, data=data)\n",
    "        \n",
    "        # Plot point estimates and error bars on top of the boxplot\n",
    "        sns.pointplot(x=group_col, y=value_col, data=data, errorbar='sd', color='red')\n",
    "        \n",
    "        # Manually add lines if you want to connect the points\n",
    "        plt.plot(data[group_col], data.groupby(group_col)[value_col].mean(), linestyle='-', color='red')\n",
    "\n",
    "        # Set plot labels and title\n",
    "        plt.title(f'Boxplot of {value_col}')\n",
    "        plt.ylabel(value_col)\n",
    "        plt.xlabel(group_col)\n",
    "        \n",
    "        # Add a grid for better readability\n",
    "        plt.grid()\n",
    "        \n",
    "        # Close the plot to avoid displaying in non-interactive environments\n",
    "        plt.close()\n",
    "        \n",
    "        # Return the current figure object\n",
    "        return plt.gcf()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error while plotting boxplot for {value_col}: {e}\")\n",
    "        return None\n",
    "        \n",
    "def plot_residuals(data, group_col, value_col):\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "    # Sanitize column names for use in the formula\n",
    "    sanitized_value_col = value_col.replace('-', '_').replace(' ', '_')\n",
    "    sanitized_group_col = group_col.replace('-', '_').replace(' ', '_')\n",
    "    \n",
    "    # Drop rows with NaN or infinite values in the relevant columns\n",
    "    data = data.dropna(subset=[value_col, group_col])\n",
    "    data = data[np.isfinite(data[value_col])]\n",
    "    \n",
    "    # Ensure there is more than one unique group and enough data to perform OLS\n",
    "    if data[sanitized_group_col].nunique() < 2 or len(data) < 2:\n",
    "        print(f\"Not enough data to fit OLS model for {value_col}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Rename columns for OLS model compatibility\n",
    "    data = data.rename(columns={value_col: sanitized_value_col, group_col: sanitized_group_col})\n",
    "    \n",
    "    # Fit the OLS model\n",
    "    formula = f'{sanitized_value_col} ~ {sanitized_group_col}'\n",
    "    try:\n",
    "        model = ols(formula, data=data).fit()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error fitting OLS model for {value_col}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    residuals = model.resid\n",
    "    fitted = model.fittedvalues\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    sns.histplot(residuals, bins=15, kde=True, ax=axs[0, 0])\n",
    "    axs[0, 0].set_title('Histogram of Residuals')\n",
    "    \n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axs[0, 1])\n",
    "    axs[0, 1].set_title('Normal Probability Plot')\n",
    "    \n",
    "    sns.scatterplot(x=fitted, y=residuals, ax=axs[1, 0])\n",
    "    axs[1, 0].axhline(0, color='r', linestyle='--')\n",
    "    axs[1, 0].set_title('Residuals vs Fitted Values')\n",
    "    \n",
    "    sns.lineplot(x=np.arange(len(residuals)), y=residuals, ax=axs[1, 1])\n",
    "    axs[1, 1].set_title('Residuals vs Order')\n",
    "    axs[1, 1].axhline(0, color='r', linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "# Plot all visualizations for each numerical column against 'GROUP'\n",
    "def plot_all_visualizations(data):\n",
    "    group_col = 'GROUP'\n",
    "    numeric_columns = data.select_dtypes(include='number').columns\n",
    "    for value_col in numeric_columns:\n",
    "        if value_col != group_col:\n",
    "            print(f\"Plotting for column: {value_col}\")\n",
    "            fig = plot_tukey_CIs(data, group_col, value_col)\n",
    "            if fig:\n",
    "                plots_dict.setdefault('tukey_CIs', []).append((value_col, fig))\n",
    "            fig = plot_interval(data, group_col, value_col)\n",
    "            plots_dict.setdefault('interval', []).append((value_col, fig))\n",
    "            fig = plot_individual_value(data, group_col, value_col)\n",
    "            plots_dict.setdefault('individual_value', []).append((value_col, fig))\n",
    "            fig = plot_boxplot(data, group_col, value_col)\n",
    "            plots_dict.setdefault('boxplot', []).append((value_col, fig))\n",
    "            fig = plot_residuals(data, group_col, value_col)\n",
    "            plots_dict.setdefault('residuals', []).append((value_col, fig))\n",
    "\n",
    "# Save plots to Excel file\n",
    "def save_plots_to_excel(plots_dict, filename):\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        for plot_type, plots in plots_dict.items():\n",
    "            worksheet_name = plot_type[:31]  # Worksheet names must be <= 31 chars\n",
    "            worksheet = writer.book.add_worksheet(worksheet_name)\n",
    "            row = 0\n",
    "            for value_col, fig in plots:\n",
    "                # Save the figure to a BytesIO object\n",
    "                img_data = io.BytesIO()\n",
    "                fig.savefig(img_data, format='png')\n",
    "                img_data.seek(0)\n",
    "                # Open the image with PIL\n",
    "                image = Image.open(img_data)\n",
    "                # Convert to a format xlsxwriter can handle\n",
    "                image_data = io.BytesIO()\n",
    "                image.save(image_data, format='png')\n",
    "                image_data.seek(0)\n",
    "                # Insert the image into the Excel sheet\n",
    "                worksheet.insert_image(row, 0, '', {'image_data': image_data})\n",
    "                worksheet.write(row, 1, value_col)\n",
    "                row += 30  # Adjust the row position for the next plot\n",
    "\n",
    "# Interact to trigger the Anderson-Darling test and proceed based on the results\n",
    "perform_anderson_darling_test()\n",
    "\n",
    "# Example usage with filtered_data\n",
    "plot_all_visualizations(filtered_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc96a310-b95c-4e47-89f5-5308bfbcac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['Core', 'Comps_Thin', 'Comps_Thick', 'Comps', 'F_Thick', 'Kfactor_Init-1', 'EdgeCol_Bot', 'EdgeCol_Top', 'L_Shrink', 'W_Shrink']\n",
      "AD Test Result = No, reject null\n",
      "p<=0.05  reject null\n",
      "Group counts:\n",
      " Attributes                GROUP  \n",
      "0.5 High Density Cgf-Cgf  EVONIK     64\n",
      "                          SILSTAB    38\n",
      "1.5 Flat Blk-Blk          EVONIK     36\n",
      "                          SILSTAB    25\n",
      "2.6 Flat Blk-Blk          EVONIK     15\n",
      "                          SILSTAB    11\n",
      "Q Taper Blk-Blk           EVONIK     23\n",
      "                          SILSTAB    18\n",
      "dtype: int64\n",
      "Number of unique groups: Attributes\n",
      "0.5 High Density Cgf-Cgf    2\n",
      "1.5 Flat Blk-Blk            2\n",
      "2.6 Flat Blk-Blk            2\n",
      "Q Taper Blk-Blk             2\n",
      "dtype: int64\n",
      "Number of unique groups for 0.5 High Density Cgf-Cgf is between 2 and 9.\n",
      "All groups in 0.5 High Density Cgf-Cgf have more than 15 records.\n",
      "Number of unique groups for 1.5 Flat Blk-Blk is between 2 and 9.\n",
      "All groups in 1.5 Flat Blk-Blk have more than 15 records.\n",
      "Number of unique groups for 2.6 Flat Blk-Blk is between 2 and 9.\n",
      "At least one group in 2.6 Flat Blk-Blk has 15 or fewer records.\n",
      "Number of unique groups for Q Taper Blk-Blk is between 2 and 9.\n",
      "All groups in Q Taper Blk-Blk have more than 15 records.\n",
      "Result from Minimum Group Records Test = No\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb7d7d97aa4490dbd469ffb8d1d6faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Choose Test:', options=('Equal Variance Test', 'Non-Parametric Tes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: Core\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: Comps_Thin\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: Comps_Thick\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: Comps\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: F_Thick\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: Kfactor_Init-1\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: EdgeCol_Bot\n",
      "Skipping Tukey HSD plot for EdgeCol_Bot: Axis limits cannot be NaN or Inf\n",
      "Not enough groups to plot boxplot for EdgeCol_Bot. Skipping.\n",
      "Not enough data to fit OLS model for EdgeCol_Bot. Skipping.\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: EdgeCol_Top\n",
      "Skipping Tukey HSD plot for EdgeCol_Top: Axis limits cannot be NaN or Inf\n",
      "Not enough groups to plot boxplot for EdgeCol_Top. Skipping.\n",
      "Not enough data to fit OLS model for EdgeCol_Top. Skipping.\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: L_Shrink\n",
      "Plotting for Attribute: 0.5 High Density Cgf-Cgf, Column: W_Shrink\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: Core\n",
      "Skipping Tukey HSD plot for Core: Axis limits cannot be NaN or Inf\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: Comps_Thin\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: Comps_Thick\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: Comps\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: F_Thick\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: Kfactor_Init-1\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: EdgeCol_Bot\n",
      "Skipping Tukey HSD plot for EdgeCol_Bot: Axis limits cannot be NaN or Inf\n",
      "Not enough groups to plot boxplot for EdgeCol_Bot. Skipping.\n",
      "Not enough data to fit OLS model for EdgeCol_Bot. Skipping.\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: EdgeCol_Top\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: L_Shrink\n",
      "Plotting for Attribute: 1.5 Flat Blk-Blk, Column: W_Shrink\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: Core\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: Comps_Thin\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: Comps_Thick\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: Comps\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: F_Thick\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: Kfactor_Init-1\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: EdgeCol_Bot\n",
      "Skipping Tukey HSD plot for EdgeCol_Bot: Axis limits cannot be NaN or Inf\n",
      "Not enough groups to plot boxplot for EdgeCol_Bot. Skipping.\n",
      "Not enough data to fit OLS model for EdgeCol_Bot. Skipping.\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: EdgeCol_Top\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: L_Shrink\n",
      "Plotting for Attribute: Q Taper Blk-Blk, Column: W_Shrink\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: Core\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: Comps_Thin\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: Comps_Thick\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: Comps\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: F_Thick\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: Kfactor_Init-1\n",
      "Skipping Tukey HSD plot for Kfactor_Init-1: Axis limits cannot be NaN or Inf\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: EdgeCol_Bot\n",
      "Skipping Tukey HSD plot for EdgeCol_Bot: Axis limits cannot be NaN or Inf\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: EdgeCol_Top\n",
      "Skipping Tukey HSD plot for EdgeCol_Top: Axis limits cannot be NaN or Inf\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: L_Shrink\n",
      "Skipping Tukey HSD plot for L_Shrink: Axis limits cannot be NaN or Inf\n",
      "Plotting for Attribute: 2.6 Flat Blk-Blk, Column: W_Shrink\n",
      "Skipping Tukey HSD plot for W_Shrink: Axis limits cannot be NaN or Inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import levene, f_oneway, kruskal, median_test\n",
    "from statsmodels.stats.weightstats import CompareMeans, DescrStatsW\n",
    "from fuzzywuzzy import fuzz\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import io\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Global variable to store results\n",
    "global_results = []\n",
    "global_levene_results = []\n",
    "global_anova_welch_results = []\n",
    "user_choice_2 = None  # Initialize user_choice_2\n",
    "plots_dict = {}  # Dictionary to store plots\n",
    "\n",
    "# Assuming filtered_data and table1_df are already loaded\n",
    "\n",
    "def anderson_darling_test(data):\n",
    "    data = np.asarray(data).flatten()\n",
    "    result = stats.anderson(data, dist='norm')\n",
    "    return result.statistic, result.critical_values, result.significance_level\n",
    "\n",
    "# Function to find representative description\n",
    "def find_representative_description(descriptions, threshold=80):\n",
    "    unique_descriptions = np.unique(descriptions)\n",
    "    representative_description = unique_descriptions[0]\n",
    "    for desc in unique_descriptions[1:]:\n",
    "        if fuzz.ratio(representative_description, desc) >= threshold:\n",
    "            continue\n",
    "        else:\n",
    "            representative_description = desc\n",
    "            break\n",
    "    return representative_description\n",
    "\n",
    "# Function to plot standard deviations\n",
    "def plot_standard_deviations(column, group_labels, means, std_devs, p_value_1, p_value_2):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.errorbar(means, group_labels, xerr=std_devs, fmt='o', capsize=5, capthick=2, elinewidth=2, linestyle='None')\n",
    "    ax.set_title(f'Test for Equal Variances: {column} vs GROUP\\nMultiple comparison intervals for the standard deviation, α = 0.05')\n",
    "    ax.set_ylabel('GROUP')\n",
    "    ax.set_xlabel('Standard Deviation')\n",
    "    plt.figtext(0.95, 0.9, f\"Multiple Comparisons\\nP-Value (Levene's Test)\\nP-Value: {p_value_1:.3f}\", bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5})\n",
    "    plt.figtext(0.95, 0.8, f\"P-Value (ANOVA or Welch)\\nP-Value: {p_value_2:.3f}\", bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5})\n",
    "    ax.set_yticks(range(len(group_labels)))\n",
    "    ax.set_yticklabels(group_labels)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "# Function to handle user's choice for EVT or NPT\n",
    "def handle_choice_1(choice):\n",
    "    global user_choice_1\n",
    "    user_choice_1 = choice\n",
    "    print(f\"User choice: {user_choice_1}\")\n",
    "    if user_choice_1 == 'Equal Variance Test':\n",
    "        equal_variance_test()\n",
    "    elif user_choice_1 == 'Non-Parametric Test':\n",
    "        check_extreme_outliers()\n",
    "\n",
    "# Function to handle user's choice for non-parametric test\n",
    "def handle_choice_2(attr, group_df):\n",
    "    def handle_choice_test(choice):\n",
    "        global user_choice_2, global_results\n",
    "        user_choice_2 = choice\n",
    "        print(f\"User choice for {attr}: {user_choice_2}\")\n",
    "\n",
    "        # Remove existing results for the chosen attribute and test type\n",
    "        global_results = [result for result in global_results if not (result['Attributes'] == attr and result['Test Conducted'] == user_choice_2)]\n",
    "        \n",
    "        if user_choice_2 == \"Mood's Median\":\n",
    "            results = moods_median_test(group_df, attr)\n",
    "        elif user_choice_2 == 'Kruskal-Wallis':\n",
    "            results = kruskal_wallis_test(group_df, attr)\n",
    "        \n",
    "        global_results.extend(results)\n",
    "        results_df = pd.DataFrame(results)\n",
    "        display(results_df)\n",
    "        return results\n",
    "\n",
    "    interact_widget = interact(handle_choice_test, choice=widgets.Dropdown(options=[\"Mood's Median\", 'Kruskal-Wallis'], description='Choose Test:'))\n",
    "    return interact_widget.widget.result\n",
    "\n",
    "# Function to check skewness and proceed\n",
    "def check_skewness_and_proceed():\n",
    "    table1_df_global['Skewness'] = pd.to_numeric(table1_df_global['Skewness'], errors='coerce')\n",
    "    skewness_check = table1_df_global['Skewness'].apply(lambda x: -2 <= x <= 2 if pd.notna(x) else True)\n",
    "    if skewness_check.all():\n",
    "        print(\"Skewness for all records is between -2 and 2. Proceed to user choice.\")\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "    else:\n",
    "        print(\"Skewness for some records is outside the range of -2 and 2. Suggesting Non-Parametric Test (NPT) instead.\")\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "\n",
    "# Perform Anderson-Darling Test\n",
    "def perform_anderson_darling_test():\n",
    "    numerical_columns = [col for col in filtered_data.columns if pd.api.types.is_numeric_dtype(filtered_data[col])]\n",
    "    print(f\"Numerical columns: {numerical_columns}\")\n",
    "    data_for_testing = filtered_data[numerical_columns].values.flatten()\n",
    "    statistic, critical_values, significance_level = anderson_darling_test(data_for_testing)\n",
    "    p_value_threshold = 0.05\n",
    "    if statistic < critical_values[2]:\n",
    "        result = \"Yes, fail to reject null\"\n",
    "        print(f\"AD Test Result = {result}\")\n",
    "        print(\"p>0.05  fail to reject null\")\n",
    "        check_skewness_and_proceed()\n",
    "    else:\n",
    "        result = \"No, reject null\"\n",
    "        print(f\"AD Test Result = {result}\")\n",
    "        print(\"p<=0.05  reject null\")\n",
    "        perform_mgrt_test()\n",
    "\n",
    "# Function to perform Minimum Group Records Test (MGRT)\n",
    "def perform_mgrt_test():\n",
    "    group_counts = filtered_data.groupby(['Attributes', 'GROUP']).size()\n",
    "    print(\"Group counts:\\n\", group_counts)\n",
    "    num_unique_groups = group_counts.groupby(level=0).size()\n",
    "    print(f\"Number of unique groups: {num_unique_groups}\")\n",
    "    result_MGRT = \"Yes\"\n",
    "    for attr, group_count in group_counts.groupby(level=0):\n",
    "        if 2 <= len(group_count) <= 9:\n",
    "            print(f\"Number of unique groups for {attr} is between 2 and 9.\")\n",
    "            if not all(group_count > 15):\n",
    "                result_MGRT = \"No\"\n",
    "                print(f\"At least one group in {attr} has 15 or fewer records.\")\n",
    "            else:\n",
    "                print(f\"All groups in {attr} have more than 15 records.\")\n",
    "        elif 10 <= len(group_count) <= 12:\n",
    "            print(f\"Number of unique groups for {attr} is between 10 and 12.\")\n",
    "            if not all(group_count > 20):\n",
    "                result_MGRT = \"No\"\n",
    "                print(f\"At least one group in {attr} has 20 or fewer records.\")\n",
    "            else:\n",
    "                print(f\"All groups in {attr} have more than 20 records.\")\n",
    "        else:\n",
    "            print(f\"Number of unique groups for {attr} is outside the specified range (2-12).\")\n",
    "    print(f\"Result from Minimum Group Records Test = {result_MGRT}\")\n",
    "    if result_MGRT == \"Yes\":\n",
    "        check_skewness_and_proceed()\n",
    "    else:\n",
    "        interact(handle_choice_1, choice=widgets.Dropdown(options=['Equal Variance Test', 'Non-Parametric Test'], description='Choose Test:'))\n",
    "\n",
    "# Function to perform Equal Variance Test\n",
    "def equal_variance_test():\n",
    "    global global_levene_results, global_anova_welch_results\n",
    "    descriptions = filtered_data['Attributes']\n",
    "    representative_description = find_representative_description(descriptions)\n",
    "    levene_results = []\n",
    "    anova_welch_results = []\n",
    "    numeric_columns = filtered_data.select_dtypes(include='number').columns\n",
    "    grouped = filtered_data.groupby('Attributes')\n",
    "    for attr, group_df in grouped:\n",
    "        print(f\"Processing group: Attributes={attr}\")\n",
    "        for column in numeric_columns:\n",
    "            if column != 'GROUP':\n",
    "                groups = group_df.groupby('GROUP')[column].apply(lambda x: x.dropna().values)\n",
    "                group_labels = [label for label, group in zip(groups.index, groups) if len(group) > 0]\n",
    "                means = [np.mean(group) for group in groups if len(group) > 0]\n",
    "                std_devs = [np.std(group) for group in groups if len(group) > 0]\n",
    "                if not means or not std_devs:\n",
    "                    continue\n",
    "                print(f\"\\nTesting column: {column}\")\n",
    "                for label, group in zip(group_labels, groups):\n",
    "                    print(f\"Group: {label}, Data: {group}\")\n",
    "                try:\n",
    "                    stat, p_value_1 = levene(*[group for group in groups if len(group) > 0])\n",
    "                    if np.isnan(p_value_1):\n",
    "                        raise ValueError(\"NaN P-Value\")\n",
    "                except:\n",
    "                    p_value_1 = np.nan\n",
    "                    levene_results.append({\n",
    "                        'Column': column,\n",
    "                        'Levene P-Value': 'N/A',\n",
    "                        'Result': 'N/A',\n",
    "                        'Attributes': attr\n",
    "                    })\n",
    "                    anova_welch_results.append({\n",
    "                        'Column': column,\n",
    "                        'ANOVA/Welch P-Value': 'N/A',\n",
    "                        'Result': 'N/A',\n",
    "                        'Test Type': 'N/A',\n",
    "                        'Attributes': attr\n",
    "                    })\n",
    "                    continue\n",
    "                levene_result = 'Equal' if p_value_1 > 0.05 else 'Diff'\n",
    "                levene_results.append({\n",
    "                    'Column': column,\n",
    "                    'Levene P-Value': p_value_1,\n",
    "                    'Levene Statistic': stat,\n",
    "                    'Result': levene_result,\n",
    "                    'Attributes': attr\n",
    "                })\n",
    "                try:\n",
    "                    if p_value_1 > 0.05:\n",
    "                        print(f\"Yes, Parametric ANOVA for {column}\")\n",
    "                        anova_result = f_oneway(*[group for group in groups if len(group) > 0])\n",
    "                        p_value_2 = anova_result.pvalue\n",
    "                        if np.isnan(p_value_2):\n",
    "                            raise ValueError(\"NaN P-Value\")\n",
    "                        if p_value_2 > 0.05:\n",
    "                            result = 'Equal'\n",
    "                            test_type = 'ANOVA'\n",
    "                        else:\n",
    "                            result = 'Diff'\n",
    "                            test_type = 'ANOVA'\n",
    "                    else:\n",
    "                        print(f\"No, Parametric Welch ANOVA for {column}\")\n",
    "                        desc_stats = [DescrStatsW(group) for group in groups if len(group) > 0]\n",
    "                        cm = CompareMeans(*desc_stats)\n",
    "                        welch_result = cm.ttest_ind(usevar='unequal')\n",
    "                        p_value_2 = welch_result[1]\n",
    "                        if np.isnan(p_value_2):\n",
    "                            raise ValueError(\"NaN P-Value\")\n",
    "                        if p_value_2 > 0.05:\n",
    "                            result = 'Equal'\n",
    "                            test_type = 'Welch ANOVA'\n",
    "                        else:\n",
    "                            result = 'Diff'\n",
    "                            test_type = 'Welch ANOVA'\n",
    "                except:\n",
    "                    p_value_2 = np.nan\n",
    "                    result = 'N/A'\n",
    "                    test_type = 'N/A'\n",
    "                fig = plot_standard_deviations(column, group_labels, means, std_devs, p_value_1, p_value_2)\n",
    "                plots_dict.setdefault('standard_deviations', []).append((f'{attr}_{column}', fig))\n",
    "                anova_welch_results.append({\n",
    "                    'Column': column,\n",
    "                    'ANOVA/Welch P-Value': p_value_2,\n",
    "                    'Result': result,\n",
    "                    'Test Type': test_type,\n",
    "                    'Attributes': attr\n",
    "                })\n",
    "    global_levene_results = pd.DataFrame(levene_results)\n",
    "    global_anova_welch_results = pd.DataFrame(anova_welch_results)\n",
    "    # Format the DataFrames as requested\n",
    "    levene_df_pivot = pd.pivot_table(global_levene_results, index='Attributes', columns='Column', values='Levene P-Value', aggfunc='first')\n",
    "    anova_welch_df_pivot = pd.pivot_table(global_anova_welch_results, index='Attributes', columns='Column', values='ANOVA/Welch P-Value', aggfunc='first')\n",
    "    # DataFrames without p-values\n",
    "    levene_df_simple = global_levene_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "    anova_welch_df_simple = global_anova_welch_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "    print(\"Levene's Test Results (with P-Values):\")\n",
    "    display(levene_df_pivot)\n",
    "    print(\"\\nANOVA/Welch Test Results (with P-Values):\")\n",
    "    display(anova_welch_df_pivot)\n",
    "    print(\"\\nLevene's Test Results (Simplified):\")\n",
    "    display(levene_df_simple)\n",
    "    print(\"\\nANOVA/Welch Test Results (Simplified):\")\n",
    "    display(anova_welch_df_simple)\n",
    "\n",
    "# Function to perform Mood's Median Test\n",
    "def moods_median_test(group_df, attr):\n",
    "    numeric_columns = group_df.select_dtypes(include='number').columns\n",
    "    results = []\n",
    "    for column in numeric_columns:\n",
    "        if column != 'GROUP':\n",
    "            groups = [group[column].dropna().values for name, group in group_df.groupby('GROUP')]\n",
    "            groups = [group for group in groups if len(group) > 0]\n",
    "            if len(groups) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                stat, p_value, med, tbl = median_test(*groups)\n",
    "                if p_value > 0.05:\n",
    "                    result = 'Equal'\n",
    "                else:\n",
    "                    result = 'Diff'\n",
    "                group_stats = group_df.groupby('GROUP')[column].describe().unstack()\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': group_stats['50%'].to_dict(),\n",
    "                    'N': group_stats['count'].to_dict(),\n",
    "                    'Q1-Q3': group_stats[['25%', '75%']].to_dict(),\n",
    "                    'H-Value': stat,\n",
    "                    'P-Value': p_value,\n",
    "                    'Result': result,\n",
    "                    'Test Conducted': \"Mood's Median\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "            except ValueError as e:\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': np.nan,\n",
    "                    'N': len(group_df),\n",
    "                    'Q1-Q3': 'N/A',\n",
    "                    'H-Value': np.nan,\n",
    "                    'P-Value': np.nan,\n",
    "                    'Result': 'N/A',\n",
    "                    'Test Conducted': \"Mood's Median\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "    return results\n",
    "\n",
    "# Function to perform Kruskal-Wallis Test\n",
    "def kruskal_wallis_test(group_df, attr):\n",
    "    numeric_columns = group_df.select_dtypes(include='number').columns\n",
    "    results = []\n",
    "    for column in numeric_columns:\n",
    "        if column != 'GROUP':\n",
    "            groups = [group[column].dropna().values for name, group in group_df.groupby('GROUP')]\n",
    "            groups = [group for group in groups if len(group) > 0]\n",
    "            if len(groups) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                stat, p_value = kruskal(*groups)\n",
    "                if p_value > 0.05:\n",
    "                    result = 'Equal'\n",
    "                else:\n",
    "                    result = 'Diff'\n",
    "                group_stats = group_df.groupby('GROUP')[column].describe().unstack()\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': group_stats['50%'].to_dict(),\n",
    "                    'N': group_stats['count'].to_dict(),\n",
    "                    'Q1-Q3': group_stats[['25%', '75%']].to_dict(),\n",
    "                    'H-Value': stat,\n",
    "                    'P-Value': p_value,\n",
    "                    'Result': result,\n",
    "                    'Test Conducted': \"Kruskal-Wallis\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "            except ValueError as e:\n",
    "                result_data = {\n",
    "                    'Attributes': attr,\n",
    "                    'Column': column,\n",
    "                    'Group': group_df['GROUP'].unique().tolist(),\n",
    "                    'Median': np.nan,\n",
    "                    'N': len(group_df),\n",
    "                    'Q1-Q3': 'N/A',\n",
    "                    'H-Value': np.nan,\n",
    "                    'P-Value': np.nan,\n",
    "                    'Result': 'N/A',\n",
    "                    'Test Conducted': \"Kruskal-Wallis\"\n",
    "                }\n",
    "                results.append(result_data)\n",
    "    return results\n",
    "\n",
    "# Function to perform tests by attribute\n",
    "def perform_tests_by_attribute():\n",
    "    all_results = []\n",
    "    for attr in filtered_data['Attributes'].unique():\n",
    "        group_df = filtered_data[filtered_data['Attributes'] == attr]\n",
    "        print(f\"\\nChoose the test to conduct for {attr}:\")\n",
    "        results_df = handle_choice_2(attr, group_df)\n",
    "        if results_df is not None:  # Ensure the results are valid\n",
    "            all_results.append(results_df)\n",
    "\n",
    "    # Collect the results from each attribute\n",
    "    all_results_list = []\n",
    "    for results_df in all_results:\n",
    "        if isinstance(results_df, list):  # Check if it's a list\n",
    "            all_results_list.extend(results_df)\n",
    "\n",
    "    # Update the global results list\n",
    "    global global_results\n",
    "    global_results.extend(all_results_list)\n",
    "\n",
    "# Function to check extreme outliers\n",
    "def check_extreme_outliers():\n",
    "    def find_extreme_outliers(series):\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        mean = series.mean()\n",
    "        outliers = series[(series < lower_bound) | (series > upper_bound)]\n",
    "        distances = (outliers - mean).abs()\n",
    "        return outliers, distances\n",
    "\n",
    "    outlier_present = False\n",
    "    outliers_list = []\n",
    "    numeric_columns = filtered_data.select_dtypes(include='number').columns\n",
    "    grouped = filtered_data.groupby('Attributes')\n",
    "    for attr, group_df in grouped:\n",
    "        for column in numeric_columns:\n",
    "            if column != 'GROUP':\n",
    "                valid_groups = group_df['GROUP'].dropna().unique()\n",
    "                if len(valid_groups) > 0:  # Ensure there are valid groups to plot\n",
    "                    groups = group_df.groupby('GROUP')[column].apply(lambda x: x.dropna().values)\n",
    "                    valid_groups = [group for group in groups if len(group) > 0]\n",
    "                    if len(valid_groups) < 2:\n",
    "                        continue\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    sns.boxplot(x='GROUP', y=column, data=group_df)\n",
    "                    plt.title(f\"Boxplot of {column} by GROUP for Attributes={attr}\")\n",
    "                    plt.close()\n",
    "                    plots_dict.setdefault('boxplot', []).append((f'{attr}_{column}', plt.gcf()))\n",
    "                for name, group in group_df.groupby('GROUP'):\n",
    "                    outliers, distances = find_extreme_outliers(group[column])\n",
    "                    if not outliers.empty:\n",
    "                        outlier_present = True\n",
    "                        print(f\"Column: {column}, Group: {name}, Attributes: {attr}\")\n",
    "                        print(\"Outliers and their distances from the mean:\")\n",
    "                        for value, distance in zip(outliers, distances):\n",
    "                            print(f\"Outlier: {value}, Distance from mean: {distance}\")\n",
    "                            outliers_list.append({\n",
    "                                'Column': column,\n",
    "                                'Group': name,\n",
    "                                'Attributes': attr,\n",
    "                                'Outlier': value,\n",
    "                                'Distance from Mean': distance\n",
    "                            })\n",
    "    result = \"Yes\" if outlier_present else \"No\"\n",
    "    print(f\"Extreme outliers present: {result}\")\n",
    "    outliers_df = pd.DataFrame(outliers_list)\n",
    "    display(outliers_df)\n",
    "    perform_tests_by_attribute()\n",
    "\n",
    "# Plotting functions for visualization\n",
    "def plot_tukey_CIs(data, group_col, value_col):\n",
    "    try:\n",
    "        from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "        tukey_result = pairwise_tukeyhsd(endog=data[value_col], groups=data[group_col], alpha=0.05)\n",
    "        tukey_result.plot_simultaneous()\n",
    "        plt.title(f'Tukey Simultaneous 95% CIs\\nDifferences of Means for {value_col}')\n",
    "        plt.xlabel('Difference of Means')\n",
    "        plt.grid()\n",
    "        plt.close()\n",
    "        return plt.gcf()\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping Tukey HSD plot for {value_col}: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_interval(data, group_col, value_col):\n",
    "    sns.pointplot(x=group_col, y=value_col, data=data, capsize=.1, errwidth=1.5, ci='sd')\n",
    "    plt.title(f'Interval Plot of {value_col} vs {group_col}\\n95% CI for the Mean')\n",
    "    plt.ylabel(value_col)\n",
    "    plt.xlabel(group_col)\n",
    "    plt.grid()\n",
    "    plt.close()\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_individual_value(data, group_col, value_col):\n",
    "    sns.stripplot(x=group_col, y=value_col, data=data, jitter=True)\n",
    "    sns.pointplot(x=group_col, y=value_col, data=data, join=True, ci='sd', color='red')\n",
    "    plt.title(f'Individual Value Plot of {value_col} vs {group_col}')\n",
    "    plt.ylabel(value_col)\n",
    "    plt.xlabel(group_col)\n",
    "    plt.grid()\n",
    "    plt.close()\n",
    "    return plt.gcf()\n",
    "\n",
    "def plot_boxplot(data, group_col, value_col):\n",
    "    # Drop rows with NaN values in the group or value columns\n",
    "    data = data.dropna(subset=[group_col, value_col])\n",
    "    \n",
    "    # Check if there are at least two groups with data\n",
    "    if data[group_col].nunique() < 2:\n",
    "        print(f\"Not enough groups to plot boxplot for {value_col}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        sns.boxplot(x=group_col, y=value_col, data=data)\n",
    "        sns.pointplot(x=group_col, y=value_col, data=data, join=True, ci='sd', color='red')\n",
    "        plt.title(f'Boxplot of {value_col}')\n",
    "        plt.ylabel(value_col)\n",
    "        plt.xlabel(group_col)\n",
    "        plt.grid()\n",
    "        plt.close()\n",
    "        return plt.gcf()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error while plotting boxplot for {value_col}: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_residuals(data, group_col, value_col):\n",
    "    from statsmodels.formula.api import ols\n",
    "\n",
    "    # Sanitize column names for use in the formula\n",
    "    sanitized_value_col = value_col.replace('-', '_').replace(' ', '_')\n",
    "    sanitized_group_col = group_col.replace('-', '_').replace(' ', '_')\n",
    "    \n",
    "    # Drop rows with NaN or infinite values in the relevant columns\n",
    "    data = data.dropna(subset=[value_col, group_col])\n",
    "    data = data[np.isfinite(data[value_col])]\n",
    "    \n",
    "    # Ensure there is more than one unique group and enough data to perform OLS\n",
    "    if data[sanitized_group_col].nunique() < 2 or len(data) < 2:\n",
    "        print(f\"Not enough data to fit OLS model for {value_col}. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    # Rename columns for OLS model compatibility\n",
    "    data = data.rename(columns={value_col: sanitized_value_col, group_col: sanitized_group_col})\n",
    "    \n",
    "    # Fit the OLS model\n",
    "    formula = f'{sanitized_value_col} ~ {sanitized_group_col}'\n",
    "    try:\n",
    "        model = ols(formula, data=data).fit()\n",
    "    except ValueError as e:\n",
    "        print(f\"Error fitting OLS model for {value_col}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    residuals = model.resid\n",
    "    fitted = model.fittedvalues\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    sns.histplot(residuals, bins=15, kde=True, ax=axs[0, 0])\n",
    "    axs[0, 0].set_title('Histogram of Residuals')\n",
    "    \n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axs[0, 1])\n",
    "    axs[0, 1].set_title('Normal Probability Plot')\n",
    "    \n",
    "    sns.scatterplot(x=fitted, y=residuals, ax=axs[1, 0])\n",
    "    axs[1, 0].axhline(0, color='r', linestyle='--')\n",
    "    axs[1, 0].set_title('Residuals vs Fitted Values')\n",
    "    \n",
    "    sns.lineplot(x=np.arange(len(residuals)), y=residuals, ax=axs[1, 1])\n",
    "    axs[1, 1].set_title('Residuals vs Order')\n",
    "    axs[1, 1].axhline(0, color='r', linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "# Adjusted function to plot all visualizations for each numerical column against 'GROUP' for each Attribute\n",
    "def plot_all_visualizations(data):\n",
    "    group_col = 'GROUP'\n",
    "    numeric_columns = data.select_dtypes(include='number').columns\n",
    "    \n",
    "    # Loop through each attribute in the data\n",
    "    for attr in data['Attributes'].unique():\n",
    "        attr_data = data[data['Attributes'] == attr]\n",
    "        \n",
    "        for value_col in numeric_columns:\n",
    "            if value_col != group_col:\n",
    "                print(f\"Plotting for Attribute: {attr}, Column: {value_col}\")\n",
    "                \n",
    "                # Create Tukey's HSD plot\n",
    "                fig = plot_tukey_CIs(attr_data, group_col, value_col)\n",
    "                if fig:\n",
    "                    plots_dict.setdefault('tukey_CIs', []).append((f'{attr}_{value_col}', fig))\n",
    "                \n",
    "                # Create Interval plot\n",
    "                fig = plot_interval(attr_data, group_col, value_col)\n",
    "                if fig:\n",
    "                    plots_dict.setdefault('interval', []).append((f'{attr}_{value_col}', fig))\n",
    "                \n",
    "                # Create Individual Value plot\n",
    "                fig = plot_individual_value(attr_data, group_col, value_col)\n",
    "                if fig:\n",
    "                    plots_dict.setdefault('individual_value', []).append((f'{attr}_{value_col}', fig))\n",
    "                \n",
    "                # Create Boxplot\n",
    "                fig = plot_boxplot(attr_data, group_col, value_col)\n",
    "                if fig:\n",
    "                    plots_dict.setdefault('boxplot', []).append((f'{attr}_{value_col}', fig))\n",
    "                \n",
    "                # Create Residuals plot\n",
    "                fig = plot_residuals(attr_data, group_col, value_col)\n",
    "                if fig:\n",
    "                    plots_dict.setdefault('residuals', []).append((f'{attr}_{value_col}', fig))\n",
    "\n",
    "# Save plots to Excel file\n",
    "def save_plots_to_excel(plots_dict, filename):\n",
    "    with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "        for plot_type, plots in plots_dict.items():\n",
    "            worksheet_name = plot_type[:31]  # Worksheet names must be <= 31 chars\n",
    "            worksheet = writer.book.add_worksheet(worksheet_name)\n",
    "            row = 0\n",
    "            for value_col, fig in plots:\n",
    "                # Save the figure to a BytesIO object\n",
    "                img_data = io.BytesIO()\n",
    "                fig.savefig(img_data, format='png')\n",
    "                img_data.seek(0)\n",
    "                # Open the image with PIL\n",
    "                image = Image.open(img_data)\n",
    "                # Convert to a format xlsxwriter can handle\n",
    "                image_data = io.BytesIO()\n",
    "                image.save(image_data, format='png')\n",
    "                image_data.seek(0)\n",
    "                # Insert the image into the Excel sheet\n",
    "                worksheet.insert_image(row, 0, '', {'image_data': image_data})\n",
    "                worksheet.write(row, 1, value_col)\n",
    "                row += 30  # Adjust the row position for the next plot\n",
    "\n",
    "# Interact to trigger the Anderson-Darling test and proceed based on the results\n",
    "perform_anderson_darling_test()\n",
    "\n",
    "# Example usage with filtered_data\n",
    "plot_all_visualizations(filtered_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffc2c2b-e975-45f3-b345-e0f1b1e1fa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test P-Values (Pivoted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5 High Density Cgf-Cgf</th>\n",
       "      <td>0.142411</td>\n",
       "      <td>0.132714</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5 Flat Blk-Blk</th>\n",
       "      <td>0.720560</td>\n",
       "      <td>0.437225</td>\n",
       "      <td>0.783853</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.287955</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6 Flat Blk-Blk</th>\n",
       "      <td>0.442408</td>\n",
       "      <td>0.794669</td>\n",
       "      <td>0.068087</td>\n",
       "      <td>0.510908</td>\n",
       "      <td>0.038112</td>\n",
       "      <td>0.628695</td>\n",
       "      <td>0.187435</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>0.799517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q Taper Blk-Blk</th>\n",
       "      <td>0.185458</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.632013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.943334</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                      Comps Comps_Thick Comps_Thin     Core EdgeCol_Bot  \\\n",
       "Attributes                                                                      \n",
       "0.5 High Density Cgf-Cgf 0.142411    0.132714   0.716330 0.116278         NaN   \n",
       "1.5 Flat Blk-Blk         0.720560    0.437225   0.783853 0.722026         NaN   \n",
       "2.6 Flat Blk-Blk         0.442408    0.794669   0.068087 0.510908    0.038112   \n",
       "Q Taper Blk-Blk          0.185458    0.016714   0.368400 0.632013         NaN   \n",
       "\n",
       "Column                   EdgeCol_Top  F_Thick Kfactor_Init-1 L_Shrink W_Shrink  \n",
       "Attributes                                                                      \n",
       "0.5 High Density Cgf-Cgf         NaN 0.024073            N/A      N/A      N/A  \n",
       "1.5 Flat Blk-Blk                 N/A 0.287955            N/A      N/A      N/A  \n",
       "2.6 Flat Blk-Blk            0.628695 0.187435            N/A 0.581987 0.799517  \n",
       "Q Taper Blk-Blk                  N/A 0.943334            N/A      N/A      N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test Statistics (Pivoted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5 High Density Cgf-Cgf</th>\n",
       "      <td>2.186030</td>\n",
       "      <td>2.297774</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>2.510072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.247794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5 Flat Blk-Blk</th>\n",
       "      <td>0.129187</td>\n",
       "      <td>0.611836</td>\n",
       "      <td>0.075931</td>\n",
       "      <td>0.127796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.149814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6 Flat Blk-Blk</th>\n",
       "      <td>0.610043</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>3.650017</td>\n",
       "      <td>0.445370</td>\n",
       "      <td>4.867328</td>\n",
       "      <td>0.240507</td>\n",
       "      <td>1.841214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312183</td>\n",
       "      <td>0.066083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q Taper Blk-Blk</th>\n",
       "      <td>1.816921</td>\n",
       "      <td>6.252426</td>\n",
       "      <td>0.828144</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                      Comps  Comps_Thick  Comps_Thin     Core  \\\n",
       "Attributes                                                            \n",
       "0.5 High Density Cgf-Cgf 2.186030     2.297774    0.132786 2.510072   \n",
       "1.5 Flat Blk-Blk         0.129187     0.611836    0.075931 0.127796   \n",
       "2.6 Flat Blk-Blk         0.610043     0.069256    3.650017 0.445370   \n",
       "Q Taper Blk-Blk          1.816921     6.252426    0.828144 0.232991   \n",
       "\n",
       "Column                    EdgeCol_Bot  EdgeCol_Top  F_Thick  Kfactor_Init-1  \\\n",
       "Attributes                                                                    \n",
       "0.5 High Density Cgf-Cgf          NaN          NaN 5.247794             NaN   \n",
       "1.5 Flat Blk-Blk                  NaN          NaN 1.149814             NaN   \n",
       "2.6 Flat Blk-Blk             4.867328     0.240507 1.841214             NaN   \n",
       "Q Taper Blk-Blk                   NaN          NaN 0.005118             NaN   \n",
       "\n",
       "Column                    L_Shrink  W_Shrink  \n",
       "Attributes                                    \n",
       "0.5 High Density Cgf-Cgf       NaN       NaN  \n",
       "1.5 Flat Blk-Blk               NaN       NaN  \n",
       "2.6 Flat Blk-Blk          0.312183  0.066083  \n",
       "Q Taper Blk-Blk                NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene's Test Results (Pivoted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5 High Density Cgf-Cgf</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diff</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5 Flat Blk-Blk</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6 Flat Blk-Blk</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q Taper Blk-Blk</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                    Comps Comps_Thick Comps_Thin   Core EdgeCol_Bot  \\\n",
       "Attributes                                                                  \n",
       "0.5 High Density Cgf-Cgf  Equal       Equal      Equal  Equal         NaN   \n",
       "1.5 Flat Blk-Blk          Equal       Equal      Equal  Equal         NaN   \n",
       "2.6 Flat Blk-Blk          Equal       Equal      Equal  Equal        Diff   \n",
       "Q Taper Blk-Blk           Equal        Diff      Equal  Equal         NaN   \n",
       "\n",
       "Column                   EdgeCol_Top F_Thick Kfactor_Init-1 L_Shrink W_Shrink  \n",
       "Attributes                                                                     \n",
       "0.5 High Density Cgf-Cgf         NaN    Diff            N/A      N/A      N/A  \n",
       "1.5 Flat Blk-Blk                 N/A   Equal            N/A      N/A      N/A  \n",
       "2.6 Flat Blk-Blk               Equal   Equal            N/A    Equal    Equal  \n",
       "Q Taper Blk-Blk                  N/A   Equal            N/A      N/A      N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA/Welch Test P-Values (Pivoted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5 High Density Cgf-Cgf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.193439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330451</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5 Flat Blk-Blk</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.197917</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6 Flat Blk-Blk</th>\n",
       "      <td>0.373999</td>\n",
       "      <td>0.077453</td>\n",
       "      <td>0.883901</td>\n",
       "      <td>0.917061</td>\n",
       "      <td>0.018865</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.321736</td>\n",
       "      <td>0.857628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q Taper Blk-Blk</th>\n",
       "      <td>0.117635</td>\n",
       "      <td>0.696022</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.708858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.968449</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                      Comps Comps_Thick Comps_Thin     Core EdgeCol_Bot  \\\n",
       "Attributes                                                                      \n",
       "0.5 High Density Cgf-Cgf 0.000000    0.039837   0.000008 0.193439         NaN   \n",
       "1.5 Flat Blk-Blk         0.000000    0.000000   0.000000 0.051126         NaN   \n",
       "2.6 Flat Blk-Blk         0.373999    0.077453   0.883901 0.917061    0.018865   \n",
       "Q Taper Blk-Blk          0.117635    0.696022   0.014775 0.708858         NaN   \n",
       "\n",
       "Column                   EdgeCol_Top  F_Thick Kfactor_Init-1 L_Shrink W_Shrink  \n",
       "Attributes                                                                      \n",
       "0.5 High Density Cgf-Cgf         NaN 0.330451            N/A      N/A      N/A  \n",
       "1.5 Flat Blk-Blk                 N/A 0.197917            N/A      N/A      N/A  \n",
       "2.6 Flat Blk-Blk            0.110370 0.582957            N/A 0.321736 0.857628  \n",
       "Q Taper Blk-Blk                  N/A 0.968449            N/A      N/A      N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA/Welch Test Results (Pivoted):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attributes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5 High Density Cgf-Cgf</th>\n",
       "      <td>Diff</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5 Flat Blk-Blk</th>\n",
       "      <td>Diff</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6 Flat Blk-Blk</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q Taper Blk-Blk</th>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                    Comps Comps_Thick Comps_Thin   Core EdgeCol_Bot  \\\n",
       "Attributes                                                                  \n",
       "0.5 High Density Cgf-Cgf   Diff        Diff       Diff  Equal         NaN   \n",
       "1.5 Flat Blk-Blk           Diff        Diff       Diff  Equal         NaN   \n",
       "2.6 Flat Blk-Blk          Equal       Equal      Equal  Equal        Diff   \n",
       "Q Taper Blk-Blk           Equal       Equal       Diff  Equal         NaN   \n",
       "\n",
       "Column                   EdgeCol_Top F_Thick Kfactor_Init-1 L_Shrink W_Shrink  \n",
       "Attributes                                                                     \n",
       "0.5 High Density Cgf-Cgf         NaN   Equal            N/A      N/A      N/A  \n",
       "1.5 Flat Blk-Blk                 N/A   Equal            N/A      N/A      N/A  \n",
       "2.6 Flat Blk-Blk               Equal   Equal            N/A    Equal    Equal  \n",
       "Q Taper Blk-Blk                  N/A   Equal            N/A      N/A      N/A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if the user choice is 'Non-Parametric Test'\n",
    "if user_choice_1 == 'Non-Parametric Test':\n",
    "    # Create a DataFrame from global_results\n",
    "    npt_results_df = pd.DataFrame(global_results)\n",
    "    \n",
    "    # Ensure the DataFrame only keeps the last occurrence of each 'Attributes'/'Column' combination\n",
    "    npt_results_df_filtered = npt_results_df.drop_duplicates(subset=['Attributes', 'Column'], keep='last')\n",
    "    \n",
    "    # Display the filtered DataFrame to the user\n",
    "    print(\"Non Paramteric Test Results:\")\n",
    "    display(npt_results_df_filtered)\n",
    "else:\n",
    "    # Pivot for Levene P-Value\n",
    "    levene_pivot_pvalue = global_levene_results.pivot(index='Attributes', columns='Column', values='Levene P-Value')\n",
    "\n",
    "    # Pivot for Levene Statistic\n",
    "    levene_pivot_statistic = global_levene_results.pivot(index='Attributes', columns='Column', values='Levene Statistic')\n",
    "\n",
    "    # Pivot for Result\n",
    "    levene_pivot_result = global_levene_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "\n",
    "    # Display the pivot tables\n",
    "    print(\"Levene's Test P-Values (Pivoted):\")\n",
    "    display(levene_pivot_pvalue)\n",
    "\n",
    "    print(\"Levene's Test Statistics (Pivoted):\")\n",
    "    display(levene_pivot_statistic)\n",
    "\n",
    "    print(\"Levene's Test Results (Pivoted):\")\n",
    "    display(levene_pivot_result)\n",
    "\n",
    "    # Pivot for ANOVA/Welch P-Value\n",
    "    anova_welch_pivot_pvalue = global_anova_welch_results.pivot(index='Attributes', columns='Column', values='ANOVA/Welch P-Value')\n",
    "\n",
    "    # Pivot for Result\n",
    "    anova_welch_pivot_result = global_anova_welch_results.pivot(index='Attributes', columns='Column', values='Result')\n",
    "\n",
    "\n",
    "    # Display the pivot tables\n",
    "    print(\"ANOVA/Welch Test P-Values (Pivoted):\")\n",
    "    display(anova_welch_pivot_pvalue)\n",
    "\n",
    "    print(\"ANOVA/Welch Test Results (Pivoted):\")\n",
    "    display(anova_welch_pivot_result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead96138-0038-4a43-b8c3-2a010eb8a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique GROUP values: ['EVONIK' 'SILSTAB']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select the Trial group from the above unique GROUP values:  SILSTAB\n",
      "Please select the Incumbent group from the above unique GROUP values:  EVONIK\n",
      "Please choose between Levene's Test or Welch's ANOVA:  Levene's Test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sample Size (Trial)</th>\n",
       "      <th>Sample Size (Incumbent)</th>\n",
       "      <th>Trial</th>\n",
       "      <th>Incumbent</th>\n",
       "      <th>Diff (Trial - Incumbent)</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Statistically Different</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>103.087000</td>\n",
       "      <td>107.776000</td>\n",
       "      <td>-4.689000</td>\n",
       "      <td>0.142411</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>101.942000</td>\n",
       "      <td>104.908000</td>\n",
       "      <td>-2.966000</td>\n",
       "      <td>0.132714</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>99.907000</td>\n",
       "      <td>107.266000</td>\n",
       "      <td>-7.359000</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Core</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>4.049000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>-0.031000</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EdgeCol_Bot</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>F_Thick</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Comps</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>21.052000</td>\n",
       "      <td>23.731000</td>\n",
       "      <td>-2.679000</td>\n",
       "      <td>0.720560</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>20.885000</td>\n",
       "      <td>23.524000</td>\n",
       "      <td>-2.639000</td>\n",
       "      <td>0.437225</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>21.195000</td>\n",
       "      <td>23.936000</td>\n",
       "      <td>-2.741000</td>\n",
       "      <td>0.783853</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Core</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>1.639000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Bot</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>F_Thick</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.466000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.287955</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Comps</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>26.538000</td>\n",
       "      <td>27.003000</td>\n",
       "      <td>-0.465000</td>\n",
       "      <td>0.442408</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>26.104000</td>\n",
       "      <td>27.119000</td>\n",
       "      <td>-1.015000</td>\n",
       "      <td>0.794669</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>26.974000</td>\n",
       "      <td>26.887000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.068087</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Core</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1.635000</td>\n",
       "      <td>1.636000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.510908</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Bot</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.038112</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.628695</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>F_Thick</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.187435</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.799517</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Comps</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21.704000</td>\n",
       "      <td>22.209000</td>\n",
       "      <td>-0.505000</td>\n",
       "      <td>0.185458</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>22.086000</td>\n",
       "      <td>21.837000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21.009000</td>\n",
       "      <td>22.213000</td>\n",
       "      <td>-1.204000</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Core</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>1.674000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.632013</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EdgeCol_Bot</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EdgeCol_Top</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>F_Thick</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>1.494000</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.943334</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product           Group  Sample Size (Trial)  \\\n",
       "0   0.5 High Density Cgf-Cgf           Comps                   38   \n",
       "1   0.5 High Density Cgf-Cgf     Comps_Thick                   38   \n",
       "2   0.5 High Density Cgf-Cgf      Comps_Thin                   38   \n",
       "3   0.5 High Density Cgf-Cgf            Core                   38   \n",
       "4   0.5 High Density Cgf-Cgf     EdgeCol_Bot                   38   \n",
       "5   0.5 High Density Cgf-Cgf     EdgeCol_Top                   38   \n",
       "6   0.5 High Density Cgf-Cgf         F_Thick                   38   \n",
       "7   0.5 High Density Cgf-Cgf  Kfactor_Init-1                   38   \n",
       "8   0.5 High Density Cgf-Cgf        L_Shrink                   38   \n",
       "9   0.5 High Density Cgf-Cgf        W_Shrink                   38   \n",
       "10          1.5 Flat Blk-Blk           Comps                   25   \n",
       "11          1.5 Flat Blk-Blk     Comps_Thick                   25   \n",
       "12          1.5 Flat Blk-Blk      Comps_Thin                   25   \n",
       "13          1.5 Flat Blk-Blk            Core                   25   \n",
       "14          1.5 Flat Blk-Blk     EdgeCol_Bot                   25   \n",
       "15          1.5 Flat Blk-Blk     EdgeCol_Top                   25   \n",
       "16          1.5 Flat Blk-Blk         F_Thick                   25   \n",
       "17          1.5 Flat Blk-Blk  Kfactor_Init-1                   25   \n",
       "18          1.5 Flat Blk-Blk        L_Shrink                   25   \n",
       "19          1.5 Flat Blk-Blk        W_Shrink                   25   \n",
       "20          2.6 Flat Blk-Blk           Comps                   11   \n",
       "21          2.6 Flat Blk-Blk     Comps_Thick                   11   \n",
       "22          2.6 Flat Blk-Blk      Comps_Thin                   11   \n",
       "23          2.6 Flat Blk-Blk            Core                   11   \n",
       "24          2.6 Flat Blk-Blk     EdgeCol_Bot                   11   \n",
       "25          2.6 Flat Blk-Blk     EdgeCol_Top                   11   \n",
       "26          2.6 Flat Blk-Blk         F_Thick                   11   \n",
       "27          2.6 Flat Blk-Blk  Kfactor_Init-1                   11   \n",
       "28          2.6 Flat Blk-Blk        L_Shrink                   11   \n",
       "29          2.6 Flat Blk-Blk        W_Shrink                   11   \n",
       "30           Q Taper Blk-Blk           Comps                   18   \n",
       "31           Q Taper Blk-Blk     Comps_Thick                   18   \n",
       "32           Q Taper Blk-Blk      Comps_Thin                   18   \n",
       "33           Q Taper Blk-Blk            Core                   18   \n",
       "34           Q Taper Blk-Blk     EdgeCol_Bot                   18   \n",
       "35           Q Taper Blk-Blk     EdgeCol_Top                   18   \n",
       "36           Q Taper Blk-Blk         F_Thick                   18   \n",
       "37           Q Taper Blk-Blk  Kfactor_Init-1                   18   \n",
       "38           Q Taper Blk-Blk        L_Shrink                   18   \n",
       "39           Q Taper Blk-Blk        W_Shrink                   18   \n",
       "\n",
       "    Sample Size (Incumbent)      Trial  Incumbent  Diff (Trial - Incumbent)  \\\n",
       "0                        64 103.087000 107.776000                 -4.689000   \n",
       "1                        64 101.942000 104.908000                 -2.966000   \n",
       "2                        64  99.907000 107.266000                 -7.359000   \n",
       "3                        64   4.049000   4.080000                 -0.031000   \n",
       "4                        64        NaN        NaN                       NaN   \n",
       "5                        64        NaN        NaN                       NaN   \n",
       "6                        64   0.445000   0.444000                  0.001000   \n",
       "7                        64   0.000000   0.000000                  0.000000   \n",
       "8                        64   0.000000   0.000000                  0.000000   \n",
       "9                        64   0.000000   0.000000                  0.000000   \n",
       "10                       36  21.052000  23.731000                 -2.679000   \n",
       "11                       36  20.885000  23.524000                 -2.639000   \n",
       "12                       36  21.195000  23.936000                 -2.741000   \n",
       "13                       36   1.639000   1.650000                 -0.011000   \n",
       "14                       36        NaN        NaN                       NaN   \n",
       "15                       36   0.000000   0.000000                  0.000000   \n",
       "16                       36   1.470000   1.466000                  0.004000   \n",
       "17                       36   0.000000   0.000000                  0.000000   \n",
       "18                       36   0.000000   0.000000                  0.000000   \n",
       "19                       36   0.000000   0.000000                  0.000000   \n",
       "20                       15  26.538000  27.003000                 -0.465000   \n",
       "21                       15  26.104000  27.119000                 -1.015000   \n",
       "22                       15  26.974000  26.887000                  0.087000   \n",
       "23                       15   1.635000   1.636000                 -0.001000   \n",
       "24                       15   0.136000   0.059000                  0.077000   \n",
       "25                       15   0.112000   0.073000                  0.039000   \n",
       "26                       15   2.600000   2.594000                  0.006000   \n",
       "27                       15   0.160000   0.160000                  0.000000   \n",
       "28                       15   0.202000   0.169000                  0.033000   \n",
       "29                       15   0.361000   0.371000                 -0.010000   \n",
       "30                       23  21.704000  22.209000                 -0.505000   \n",
       "31                       23  22.086000  21.837000                  0.249000   \n",
       "32                       23  21.009000  22.213000                 -1.204000   \n",
       "33                       23   1.678000   1.674000                  0.004000   \n",
       "34                       23        NaN        NaN                       NaN   \n",
       "35                       23   0.000000   0.000000                  0.000000   \n",
       "36                       23   1.494000   1.495000                 -0.001000   \n",
       "37                       23   0.000000   0.000000                  0.000000   \n",
       "38                       23   0.000000   0.000000                  0.000000   \n",
       "39                       23   0.000000   0.000000                  0.000000   \n",
       "\n",
       "    P-Value Statistically Different  \n",
       "0  0.142411                      NO  \n",
       "1  0.132714                      NO  \n",
       "2  0.716330                      NO  \n",
       "3  0.116278                      NO  \n",
       "4       NaN                      NO  \n",
       "5       NaN                      NO  \n",
       "6  0.024073                     YES  \n",
       "7       NaN                      NO  \n",
       "8       NaN                      NO  \n",
       "9       NaN                      NO  \n",
       "10 0.720560                      NO  \n",
       "11 0.437225                      NO  \n",
       "12 0.783853                      NO  \n",
       "13 0.722026                      NO  \n",
       "14      NaN                      NO  \n",
       "15      NaN                      NO  \n",
       "16 0.287955                      NO  \n",
       "17      NaN                      NO  \n",
       "18      NaN                      NO  \n",
       "19      NaN                      NO  \n",
       "20 0.442408                      NO  \n",
       "21 0.794669                      NO  \n",
       "22 0.068087                      NO  \n",
       "23 0.510908                      NO  \n",
       "24 0.038112                     YES  \n",
       "25 0.628695                      NO  \n",
       "26 0.187435                      NO  \n",
       "27      NaN                      NO  \n",
       "28 0.581987                      NO  \n",
       "29 0.799517                      NO  \n",
       "30 0.185458                      NO  \n",
       "31 0.016714                     YES  \n",
       "32 0.368400                      NO  \n",
       "33 0.632013                      NO  \n",
       "34      NaN                      NO  \n",
       "35      NaN                      NO  \n",
       "36 0.943334                      NO  \n",
       "37      NaN                      NO  \n",
       "38      NaN                      NO  \n",
       "39      NaN                      NO  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the unique GROUP values for selection\n",
    "unique_groups = table1_df_global['GROUP'].unique()\n",
    "print(\"Unique GROUP values:\", unique_groups)\n",
    "\n",
    "# User input for selecting Trial and Incumbent groups\n",
    "trial_group = input(\"Please select the Trial group from the above unique GROUP values: \")\n",
    "incumbent_group = input(\"Please select the Incumbent group from the above unique GROUP values: \")\n",
    "\n",
    "test_choice=user_choice_1\n",
    "\n",
    "if test_choice == 'Equal Variance Test':\n",
    "    # Transform Levene's Test results table\n",
    "    levene_melted = levene_pivot_pvalue.reset_index().melt(id_vars=['Attributes'], var_name='Column', value_name='P-Value')\n",
    "    levene_melted = levene_melted.dropna(subset=['P-Value'])\n",
    "\n",
    "    # Transform ANOVA Welch's Test results table\n",
    "    anova_melted = anova_welch_pivot_pvalue.reset_index().melt(id_vars=['Attributes'], var_name='Column', value_name='P-Value')\n",
    "    anova_melted = anova_melted.dropna(subset=['P-Value'])\n",
    "\n",
    "# Get the corresponding p-values based on the user's choice\n",
    "if test_choice == 'Non-Parametric Test':\n",
    "    p_values = npt_results_df_filtered[['Attributes','Column','P-Value']]\n",
    "elif test_choice == 'Equal Variance Test':\n",
    "    equal_variance_choice = input(\"Please choose between Levene's Test or Welch's ANOVA: \").strip().lower()\n",
    "    if equal_variance_choice == \"levene's test\":\n",
    "        p_values = levene_melted[['Attributes','Column','P-Value']]\n",
    "    elif equal_variance_choice == \"welch's anova\":\n",
    "        p_values = anova_melted[['Attributes','Column','P-Value']]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice for Equal Variance Test.\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid test choice.\")\n",
    "\n",
    "# Create the desired table\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Filter the necessary data\n",
    "trial_data = table1_df_global[table1_df_global['GROUP'] == trial_group]\n",
    "incumbent_data = table1_df_global[table1_df_global['GROUP'] == incumbent_group]\n",
    "\n",
    "\n",
    "# Merge trial and incumbent data based on the 'Attributes' column\n",
    "merged_data = pd.merge(trial_data, incumbent_data, on=['Attributes','Variable'], suffixes=('_Trial', '_Incumbent'))\n",
    "\n",
    "# Ensure the numerical columns are of numeric type\n",
    "merged_data['Mean_Trial'] = pd.to_numeric(merged_data['Mean_Trial'], errors='coerce')\n",
    "merged_data['Mean_Incumbent'] = pd.to_numeric(merged_data['Mean_Incumbent'], errors='coerce')\n",
    "merged_data['N_Trial'] = pd.to_numeric(merged_data['N_Trial'], errors='coerce')\n",
    "merged_data['N_Incumbent'] = pd.to_numeric(merged_data['N_Incumbent'], errors='coerce')\n",
    "\n",
    "# Calculate the required columns\n",
    "result_df['Product'] = merged_data['Attributes']\n",
    "result_df['Group'] = merged_data['Variable']\n",
    "result_df['Sample Size (Trial)'] = merged_data['N_Trial']\n",
    "result_df['Sample Size (Incumbent)'] = merged_data['N_Incumbent']\n",
    "result_df['Trial'] = merged_data['Mean_Trial']\n",
    "result_df['Incumbent'] = merged_data['Mean_Incumbent']\n",
    "result_df['Diff (Trial - Incumbent)'] = merged_data['Mean_Trial'] - merged_data['Mean_Incumbent']\n",
    "\n",
    "# Merge p-values with the result_df\n",
    "result_df = result_df.merge(p_values, left_on=['Product','Group'], right_on=['Attributes','Column'], how='left')\n",
    "\n",
    "# Convert P-Value column to numeric, coercing errors to NaN\n",
    "result_df['P-Value'] = pd.to_numeric(result_df['P-Value'], errors='coerce')\n",
    "\n",
    "# Calculate Statistically Different column\n",
    "result_df['Statistically Different'] = result_df['P-Value'] < 0.05\n",
    "result_df['Statistically Different'] = result_df['Statistically Different'].apply(lambda x: 'YES' if x else 'NO')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df=result_df.drop(columns=['Column','Attributes'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9135b5-3129-40bd-93d3-6ee811f2a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame\n",
    "pivot_df = result_df.melt(id_vars=['Product', 'Group'], \n",
    "                   value_vars=['Sample Size (Trial)', 'Sample Size (Incumbent)', 'Trial', 'Incumbent', 'Diff (Trial - Incumbent)', 'P-Value', 'Statistically Different'],\n",
    "                   var_name='Metric', value_name='Value')\n",
    "\n",
    "pivot_df = pivot_df.pivot_table(index=['Product', 'Metric'], columns='Group', values='Value', aggfunc='first').reset_index()\n",
    "\n",
    "# Flatten the columns\n",
    "pivot_df.columns = ['_'.join(col).strip() if type(col) is tuple else col for col in pivot_df.columns.values]\n",
    "pivot_df = pivot_df.rename(columns={'Product_': 'Product', 'Metric_': 'Metric'})\n",
    "\n",
    "# Define the desired order of metrics\n",
    "metric_order = [\n",
    "    'Sample Size (Trial)', 'Sample Size (Incumbent)', 'Trial', 'Incumbent',\n",
    "    'Diff (Trial - Incumbent)', 'P-Value', 'Statistically Different'\n",
    "]\n",
    "\n",
    "# Sort the DataFrame by Product and Metric according to the defined order\n",
    "pivot_df['Metric'] = pd.Categorical(pivot_df['Metric'], categories=metric_order, ordered=True)\n",
    "pivot_df = pivot_df.sort_values(by=['Product', 'Metric']).reset_index(drop=True)\n",
    "table3_df_global=pivot_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11b6fb5-695c-4e5e-ba8b-8fe64f1e896e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Trial</td>\n",
       "      <td>103.087000</td>\n",
       "      <td>101.942000</td>\n",
       "      <td>99.907000</td>\n",
       "      <td>4.049000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>107.776000</td>\n",
       "      <td>104.908000</td>\n",
       "      <td>107.266000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-4.689000</td>\n",
       "      <td>-2.966000</td>\n",
       "      <td>-7.359000</td>\n",
       "      <td>-0.031000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.142411</td>\n",
       "      <td>0.132714</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>21.052000</td>\n",
       "      <td>20.885000</td>\n",
       "      <td>21.195000</td>\n",
       "      <td>1.639000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>23.731000</td>\n",
       "      <td>23.524000</td>\n",
       "      <td>23.936000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.466000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-2.679000</td>\n",
       "      <td>-2.639000</td>\n",
       "      <td>-2.741000</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.720560</td>\n",
       "      <td>0.437225</td>\n",
       "      <td>0.783853</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>26.538000</td>\n",
       "      <td>26.104000</td>\n",
       "      <td>26.974000</td>\n",
       "      <td>1.635000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>27.003000</td>\n",
       "      <td>27.119000</td>\n",
       "      <td>26.887000</td>\n",
       "      <td>1.636000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-0.465000</td>\n",
       "      <td>-1.015000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>-0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.442408</td>\n",
       "      <td>0.794669</td>\n",
       "      <td>0.068087</td>\n",
       "      <td>0.510908</td>\n",
       "      <td>0.038112</td>\n",
       "      <td>0.628695</td>\n",
       "      <td>0.187435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>0.799517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>21.704000</td>\n",
       "      <td>22.086000</td>\n",
       "      <td>21.009000</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.494000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>22.209000</td>\n",
       "      <td>21.837000</td>\n",
       "      <td>22.213000</td>\n",
       "      <td>1.674000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-0.505000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>-1.204000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.185458</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.632013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product                    Metric      Comps Comps_Thick  \\\n",
       "0   0.5 High Density Cgf-Cgf       Sample Size (Trial)         38          38   \n",
       "1   0.5 High Density Cgf-Cgf   Sample Size (Incumbent)         64          64   \n",
       "2   0.5 High Density Cgf-Cgf                     Trial 103.087000  101.942000   \n",
       "3   0.5 High Density Cgf-Cgf                 Incumbent 107.776000  104.908000   \n",
       "4   0.5 High Density Cgf-Cgf  Diff (Trial - Incumbent)  -4.689000   -2.966000   \n",
       "5   0.5 High Density Cgf-Cgf                   P-Value   0.142411    0.132714   \n",
       "6   0.5 High Density Cgf-Cgf   Statistically Different         NO          NO   \n",
       "7           1.5 Flat Blk-Blk       Sample Size (Trial)         25          25   \n",
       "8           1.5 Flat Blk-Blk   Sample Size (Incumbent)         36          36   \n",
       "9           1.5 Flat Blk-Blk                     Trial  21.052000   20.885000   \n",
       "10          1.5 Flat Blk-Blk                 Incumbent  23.731000   23.524000   \n",
       "11          1.5 Flat Blk-Blk  Diff (Trial - Incumbent)  -2.679000   -2.639000   \n",
       "12          1.5 Flat Blk-Blk                   P-Value   0.720560    0.437225   \n",
       "13          1.5 Flat Blk-Blk   Statistically Different         NO          NO   \n",
       "14          2.6 Flat Blk-Blk       Sample Size (Trial)         11          11   \n",
       "15          2.6 Flat Blk-Blk   Sample Size (Incumbent)         15          15   \n",
       "16          2.6 Flat Blk-Blk                     Trial  26.538000   26.104000   \n",
       "17          2.6 Flat Blk-Blk                 Incumbent  27.003000   27.119000   \n",
       "18          2.6 Flat Blk-Blk  Diff (Trial - Incumbent)  -0.465000   -1.015000   \n",
       "19          2.6 Flat Blk-Blk                   P-Value   0.442408    0.794669   \n",
       "20          2.6 Flat Blk-Blk   Statistically Different         NO          NO   \n",
       "21           Q Taper Blk-Blk       Sample Size (Trial)         18          18   \n",
       "22           Q Taper Blk-Blk   Sample Size (Incumbent)         23          23   \n",
       "23           Q Taper Blk-Blk                     Trial  21.704000   22.086000   \n",
       "24           Q Taper Blk-Blk                 Incumbent  22.209000   21.837000   \n",
       "25           Q Taper Blk-Blk  Diff (Trial - Incumbent)  -0.505000    0.249000   \n",
       "26           Q Taper Blk-Blk                   P-Value   0.185458    0.016714   \n",
       "27           Q Taper Blk-Blk   Statistically Different         NO         YES   \n",
       "\n",
       "   Comps_Thin      Core EdgeCol_Bot EdgeCol_Top   F_Thick Kfactor_Init-1  \\\n",
       "0          38        38          38          38        38             38   \n",
       "1          64        64          64          64        64             64   \n",
       "2   99.907000  4.049000         NaN         NaN  0.445000       0.000000   \n",
       "3  107.266000  4.080000         NaN         NaN  0.444000       0.000000   \n",
       "4   -7.359000 -0.031000         NaN         NaN  0.001000       0.000000   \n",
       "5    0.716330  0.116278         NaN         NaN  0.024073            NaN   \n",
       "6          NO        NO          NO          NO       YES             NO   \n",
       "7          25        25          25          25        25             25   \n",
       "8          36        36          36          36        36             36   \n",
       "9   21.195000  1.639000         NaN    0.000000  1.470000       0.000000   \n",
       "10  23.936000  1.650000         NaN    0.000000  1.466000       0.000000   \n",
       "11  -2.741000 -0.011000         NaN    0.000000  0.004000       0.000000   \n",
       "12   0.783853  0.722026         NaN         NaN  0.287955            NaN   \n",
       "13         NO        NO          NO          NO        NO             NO   \n",
       "14         11        11          11          11        11             11   \n",
       "15         15        15          15          15        15             15   \n",
       "16  26.974000  1.635000    0.136000    0.112000  2.600000       0.160000   \n",
       "17  26.887000  1.636000    0.059000    0.073000  2.594000       0.160000   \n",
       "18   0.087000 -0.001000    0.077000    0.039000  0.006000       0.000000   \n",
       "19   0.068087  0.510908    0.038112    0.628695  0.187435            NaN   \n",
       "20         NO        NO         YES          NO        NO             NO   \n",
       "21         18        18          18          18        18             18   \n",
       "22         23        23          23          23        23             23   \n",
       "23  21.009000  1.678000         NaN    0.000000  1.494000       0.000000   \n",
       "24  22.213000  1.674000         NaN    0.000000  1.495000       0.000000   \n",
       "25  -1.204000  0.004000         NaN    0.000000 -0.001000       0.000000   \n",
       "26   0.368400  0.632013         NaN         NaN  0.943334            NaN   \n",
       "27         NO        NO          NO          NO        NO             NO   \n",
       "\n",
       "   L_Shrink  W_Shrink  \n",
       "0        38        38  \n",
       "1        64        64  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.000000  \n",
       "5       NaN       NaN  \n",
       "6        NO        NO  \n",
       "7        25        25  \n",
       "8        36        36  \n",
       "9  0.000000  0.000000  \n",
       "10 0.000000  0.000000  \n",
       "11 0.000000  0.000000  \n",
       "12      NaN       NaN  \n",
       "13       NO        NO  \n",
       "14       11        11  \n",
       "15       15        15  \n",
       "16 0.202000  0.361000  \n",
       "17 0.169000  0.371000  \n",
       "18 0.033000 -0.010000  \n",
       "19 0.581987  0.799517  \n",
       "20       NO        NO  \n",
       "21       18        18  \n",
       "22       23        23  \n",
       "23 0.000000  0.000000  \n",
       "24 0.000000  0.000000  \n",
       "25 0.000000  0.000000  \n",
       "26      NaN       NaN  \n",
       "27       NO        NO  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec474d9-ce53-498c-ac86-58eeda66e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e138f71-0b87-4273-95ef-2ad11da6c283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Statistically Diff</th>\n",
       "      <th>Avg Measured Diff</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>F_Thick</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>EdgeCol_Bot</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Product       Metric Statistically Diff  \\\n",
       "0  0.5 High Density Cgf-Cgf      F_Thick                Yes   \n",
       "1          2.6 Flat Blk-Blk  EdgeCol_Bot                Yes   \n",
       "2           Q Taper Blk-Blk  Comps_Thick                Yes   \n",
       "\n",
       "   Avg Measured Diff Assessment  \n",
       "0           0.001000     Higher  \n",
       "1           0.077000     Higher  \n",
       "2           0.249000     Higher  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming table3_df_global is already defined\n",
    "# Filter the DataFrame to include only rows where the Metric is 'P-Value' or 'Diff (Trial - Incumbent)'\n",
    "filtered_df = table3_df_global[table3_df_global['Metric'].isin(['P-Value', 'Diff (Trial - Incumbent)'])]\n",
    "\n",
    "# Convert columns to numeric except 'Product' and 'Metric'\n",
    "columns_to_convert = filtered_df.columns.difference(['Product', 'Metric'])\n",
    "filtered_df[columns_to_convert] = filtered_df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace 0 with NaN to ignore them in calculations\n",
    "filtered_df = filtered_df.replace(0, np.nan)\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each product\n",
    "for product in filtered_df['Product'].unique():\n",
    "    # Filter for the current product\n",
    "    product_df = filtered_df[filtered_df['Product'] == product]\n",
    "\n",
    "    # Get the P-values and differences\n",
    "    p_values = product_df[product_df['Metric'] == 'P-Value']\n",
    "    diffs = product_df[product_df['Metric'] == 'Diff (Trial - Incumbent)']\n",
    "    \n",
    "    # Iterate over each metric\n",
    "    for col in columns_to_convert:\n",
    "        p_value = p_values[col].values[0] if col in p_values.columns else np.nan\n",
    "        diff_value = diffs[col].values[0] if col in diffs.columns else np.nan\n",
    "        \n",
    "        # Determine if statistically different\n",
    "        stat_diff = 'Yes' if not np.isnan(p_value) and p_value < 0.05 else 'No'\n",
    "        \n",
    "        # Determine assessment\n",
    "        assessment = 'Higher' if diff_value > 0 else 'Lower' if diff_value < 0 else 'N/A'\n",
    "        \n",
    "        # Append the result if Statistically Different is Yes\n",
    "        if stat_diff == 'Yes':\n",
    "            results.append({\n",
    "                'Product': product,\n",
    "                'Metric': col,\n",
    "                'Statistically Diff': stat_diff,\n",
    "                'Avg Measured Diff': diff_value,\n",
    "                'Assessment': assessment\n",
    "            })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "table4_df_global = pd.DataFrame(results)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "table4_df_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bcae0fb-803f-4c07-a916-130855faf3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metric</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Diff (Trial - Incumbent)</th>\n",
       "      <th>P-Value</th>\n",
       "      <th>Statistically Different</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comps</td>\n",
       "      <td>-3.684000</td>\n",
       "      <td>0.431485</td>\n",
       "      <td>No</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>-2.802500</td>\n",
       "      <td>0.284970</td>\n",
       "      <td>No</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>-5.050000</td>\n",
       "      <td>0.750091</td>\n",
       "      <td>No</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>0.419152</td>\n",
       "      <td>No</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F_Thick</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.156014</td>\n",
       "      <td>No</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric      Metrics  Diff (Trial - Incumbent)  P-Value  \\\n",
       "0             Comps                 -3.684000 0.431485   \n",
       "1       Comps_Thick                 -2.802500 0.284970   \n",
       "2        Comps_Thin                 -5.050000 0.750091   \n",
       "3              Core                 -0.021000 0.419152   \n",
       "4           F_Thick                  0.002500 0.156014   \n",
       "\n",
       "Metric Statistically Different Assessment  \n",
       "0                           No      Lower  \n",
       "1                           No      Lower  \n",
       "2                           No      Lower  \n",
       "3                           No      Lower  \n",
       "4                           No     Higher  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming table3_df_global is already defined\n",
    "# Filter the DataFrame to include only rows where the Metric is 'P-Value'\n",
    "p_value_df = table3_df_global[table3_df_global['Metric'] == 'P-Value']\n",
    "\n",
    "# Convert columns to numeric except 'Product' and 'Metric'\n",
    "columns_to_convert = p_value_df.columns.difference(['Product', 'Metric'])\n",
    "p_value_df[columns_to_convert] = p_value_df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Identify the numeric columns (excluding 'Product' and 'Metric')\n",
    "numeric_columns = p_value_df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Replace 0 with NaN to ignore them in mean calculations\n",
    "p_value_df = p_value_df.replace(0, np.nan)\n",
    "\n",
    "# Calculate the average P-value for each Metric across all numeric columns, ignoring 0 and NaN\n",
    "average_p_values = p_value_df.groupby(['Metric'])[numeric_columns].mean().reset_index()\n",
    "\n",
    "# Filter and process the DataFrame for 'P-Value' and 'Diff (Trial - Incumbent)'\n",
    "filtered_df = table3_df_global[table3_df_global['Metric'].isin(['P-Value', 'Diff (Trial - Incumbent)'])]\n",
    "\n",
    "# Convert columns to numeric except 'Metric'\n",
    "filtered_df[columns_to_convert] = filtered_df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace 0 with NaN to ignore them in mean calculations\n",
    "filtered_df = filtered_df.replace(0, np.nan)\n",
    "\n",
    "# Calculate the average for each Metric across all numeric columns\n",
    "average_values = filtered_df.groupby(['Metric'])[numeric_columns].mean().reset_index()\n",
    "\n",
    "# Transpose the DataFrame and add 'Statistically Different' and 'Assessment' columns\n",
    "average_values = average_values.set_index('Metric').T.reset_index().rename(columns={'index': 'Metric'})\n",
    "\n",
    "average_values['Statistically Different'] = average_values['P-Value'].apply(\n",
    "    lambda x: 'Yes' if x < 0.05 else 'N/A' if np.isnan(x) else 'No'\n",
    ")\n",
    "average_values['Assessment'] = average_values['Diff (Trial - Incumbent)'].apply(\n",
    "    lambda x: 'Higher' if x > 0 else 'N/A' if np.isnan(x) else 'Lower'\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_values = average_values.rename(columns={'Metric': 'Metrics'})\n",
    "\n",
    "# Select and reorder the relevant columns\n",
    "table4_df_global = average_values[['Metrics', 'Diff (Trial - Incumbent)', 'P-Value', 'Statistically Different', 'Assessment']]\n",
    "\n",
    "table4_df_global\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b0acf8b-2a79-4753-97f9-0f3556e2baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the user choice is 'Non-Parametric Test'\n",
    "if user_choice_1 == 'Non-Parametric Test':\n",
    "    # Create a DataFrame from global_results\n",
    "    table2_df_global=npt_results_df_filtered\n",
    "else:\n",
    "    table2_df_global=levene_pivot_result\n",
    "\n",
    "table2_df_global=table2_df_global.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00113557-3bba-439e-bbfd-f880e6e531fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>Product</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diff</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Diff</td>\n",
       "      <td>Equal</td>\n",
       "      <td>Equal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Equal</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column                   Product  Comps Comps_Thick Comps_Thin   Core  \\\n",
       "0       0.5 High Density Cgf-Cgf  Equal       Equal      Equal  Equal   \n",
       "1               1.5 Flat Blk-Blk  Equal       Equal      Equal  Equal   \n",
       "2               2.6 Flat Blk-Blk  Equal       Equal      Equal  Equal   \n",
       "3                Q Taper Blk-Blk  Equal        Diff      Equal  Equal   \n",
       "\n",
       "Column EdgeCol_Bot EdgeCol_Top F_Thick Kfactor_Init-1 L_Shrink W_Shrink  \n",
       "0              NaN         NaN    Diff            N/A      N/A      N/A  \n",
       "1              NaN         N/A   Equal            N/A      N/A      N/A  \n",
       "2             Diff       Equal   Equal            N/A    Equal    Equal  \n",
       "3              NaN         N/A   Equal            N/A      N/A      N/A  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2_df_global=table2_df_global.rename(columns={'Attributes':'Product'})\n",
    "table2_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9643b895-a251-47de-88fd-1bd7b16bcb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Comps</th>\n",
       "      <th>Comps_Thick</th>\n",
       "      <th>Comps_Thin</th>\n",
       "      <th>Core</th>\n",
       "      <th>EdgeCol_Bot</th>\n",
       "      <th>EdgeCol_Top</th>\n",
       "      <th>F_Thick</th>\n",
       "      <th>Kfactor_Init-1</th>\n",
       "      <th>L_Shrink</th>\n",
       "      <th>W_Shrink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Trial</td>\n",
       "      <td>103.087000</td>\n",
       "      <td>101.942000</td>\n",
       "      <td>99.907000</td>\n",
       "      <td>4.049000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>107.776000</td>\n",
       "      <td>104.908000</td>\n",
       "      <td>107.266000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-4.689000</td>\n",
       "      <td>-2.966000</td>\n",
       "      <td>-7.359000</td>\n",
       "      <td>-0.031000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.142411</td>\n",
       "      <td>0.132714</td>\n",
       "      <td>0.716330</td>\n",
       "      <td>0.116278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>21.052000</td>\n",
       "      <td>20.885000</td>\n",
       "      <td>21.195000</td>\n",
       "      <td>1.639000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>23.731000</td>\n",
       "      <td>23.524000</td>\n",
       "      <td>23.936000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.466000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-2.679000</td>\n",
       "      <td>-2.639000</td>\n",
       "      <td>-2.741000</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.720560</td>\n",
       "      <td>0.437225</td>\n",
       "      <td>0.783853</td>\n",
       "      <td>0.722026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.5 Flat Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>26.538000</td>\n",
       "      <td>26.104000</td>\n",
       "      <td>26.974000</td>\n",
       "      <td>1.635000</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>27.003000</td>\n",
       "      <td>27.119000</td>\n",
       "      <td>26.887000</td>\n",
       "      <td>1.636000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>2.594000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-0.465000</td>\n",
       "      <td>-1.015000</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>-0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.442408</td>\n",
       "      <td>0.794669</td>\n",
       "      <td>0.068087</td>\n",
       "      <td>0.510908</td>\n",
       "      <td>0.038112</td>\n",
       "      <td>0.628695</td>\n",
       "      <td>0.187435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>0.799517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.6 Flat Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Sample Size (Trial)</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Sample Size (Incumbent)</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Trial</td>\n",
       "      <td>21.704000</td>\n",
       "      <td>22.086000</td>\n",
       "      <td>21.009000</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.494000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Incumbent</td>\n",
       "      <td>22.209000</td>\n",
       "      <td>21.837000</td>\n",
       "      <td>22.213000</td>\n",
       "      <td>1.674000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.495000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Diff (Trial - Incumbent)</td>\n",
       "      <td>-0.505000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>-1.204000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>P-Value</td>\n",
       "      <td>0.185458</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>0.632013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>Statistically Different</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Product                    Metric      Comps Comps_Thick  \\\n",
       "0   0.5 High Density Cgf-Cgf       Sample Size (Trial)         38          38   \n",
       "1   0.5 High Density Cgf-Cgf   Sample Size (Incumbent)         64          64   \n",
       "2   0.5 High Density Cgf-Cgf                     Trial 103.087000  101.942000   \n",
       "3   0.5 High Density Cgf-Cgf                 Incumbent 107.776000  104.908000   \n",
       "4   0.5 High Density Cgf-Cgf  Diff (Trial - Incumbent)  -4.689000   -2.966000   \n",
       "5   0.5 High Density Cgf-Cgf                   P-Value   0.142411    0.132714   \n",
       "6   0.5 High Density Cgf-Cgf   Statistically Different         NO          NO   \n",
       "7           1.5 Flat Blk-Blk       Sample Size (Trial)         25          25   \n",
       "8           1.5 Flat Blk-Blk   Sample Size (Incumbent)         36          36   \n",
       "9           1.5 Flat Blk-Blk                     Trial  21.052000   20.885000   \n",
       "10          1.5 Flat Blk-Blk                 Incumbent  23.731000   23.524000   \n",
       "11          1.5 Flat Blk-Blk  Diff (Trial - Incumbent)  -2.679000   -2.639000   \n",
       "12          1.5 Flat Blk-Blk                   P-Value   0.720560    0.437225   \n",
       "13          1.5 Flat Blk-Blk   Statistically Different         NO          NO   \n",
       "14          2.6 Flat Blk-Blk       Sample Size (Trial)         11          11   \n",
       "15          2.6 Flat Blk-Blk   Sample Size (Incumbent)         15          15   \n",
       "16          2.6 Flat Blk-Blk                     Trial  26.538000   26.104000   \n",
       "17          2.6 Flat Blk-Blk                 Incumbent  27.003000   27.119000   \n",
       "18          2.6 Flat Blk-Blk  Diff (Trial - Incumbent)  -0.465000   -1.015000   \n",
       "19          2.6 Flat Blk-Blk                   P-Value   0.442408    0.794669   \n",
       "20          2.6 Flat Blk-Blk   Statistically Different         NO          NO   \n",
       "21           Q Taper Blk-Blk       Sample Size (Trial)         18          18   \n",
       "22           Q Taper Blk-Blk   Sample Size (Incumbent)         23          23   \n",
       "23           Q Taper Blk-Blk                     Trial  21.704000   22.086000   \n",
       "24           Q Taper Blk-Blk                 Incumbent  22.209000   21.837000   \n",
       "25           Q Taper Blk-Blk  Diff (Trial - Incumbent)  -0.505000    0.249000   \n",
       "26           Q Taper Blk-Blk                   P-Value   0.185458    0.016714   \n",
       "27           Q Taper Blk-Blk   Statistically Different         NO         YES   \n",
       "\n",
       "   Comps_Thin      Core EdgeCol_Bot EdgeCol_Top   F_Thick Kfactor_Init-1  \\\n",
       "0          38        38          38          38        38             38   \n",
       "1          64        64          64          64        64             64   \n",
       "2   99.907000  4.049000         NaN         NaN  0.445000       0.000000   \n",
       "3  107.266000  4.080000         NaN         NaN  0.444000       0.000000   \n",
       "4   -7.359000 -0.031000         NaN         NaN  0.001000       0.000000   \n",
       "5    0.716330  0.116278         NaN         NaN  0.024073            NaN   \n",
       "6          NO        NO          NO          NO       YES             NO   \n",
       "7          25        25          25          25        25             25   \n",
       "8          36        36          36          36        36             36   \n",
       "9   21.195000  1.639000         NaN    0.000000  1.470000       0.000000   \n",
       "10  23.936000  1.650000         NaN    0.000000  1.466000       0.000000   \n",
       "11  -2.741000 -0.011000         NaN    0.000000  0.004000       0.000000   \n",
       "12   0.783853  0.722026         NaN         NaN  0.287955            NaN   \n",
       "13         NO        NO          NO          NO        NO             NO   \n",
       "14         11        11          11          11        11             11   \n",
       "15         15        15          15          15        15             15   \n",
       "16  26.974000  1.635000    0.136000    0.112000  2.600000       0.160000   \n",
       "17  26.887000  1.636000    0.059000    0.073000  2.594000       0.160000   \n",
       "18   0.087000 -0.001000    0.077000    0.039000  0.006000       0.000000   \n",
       "19   0.068087  0.510908    0.038112    0.628695  0.187435            NaN   \n",
       "20         NO        NO         YES          NO        NO             NO   \n",
       "21         18        18          18          18        18             18   \n",
       "22         23        23          23          23        23             23   \n",
       "23  21.009000  1.678000         NaN    0.000000  1.494000       0.000000   \n",
       "24  22.213000  1.674000         NaN    0.000000  1.495000       0.000000   \n",
       "25  -1.204000  0.004000         NaN    0.000000 -0.001000       0.000000   \n",
       "26   0.368400  0.632013         NaN         NaN  0.943334            NaN   \n",
       "27         NO        NO          NO          NO        NO             NO   \n",
       "\n",
       "   L_Shrink  W_Shrink  \n",
       "0        38        38  \n",
       "1        64        64  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.000000  \n",
       "5       NaN       NaN  \n",
       "6        NO        NO  \n",
       "7        25        25  \n",
       "8        36        36  \n",
       "9  0.000000  0.000000  \n",
       "10 0.000000  0.000000  \n",
       "11 0.000000  0.000000  \n",
       "12      NaN       NaN  \n",
       "13       NO        NO  \n",
       "14       11        11  \n",
       "15       15        15  \n",
       "16 0.202000  0.361000  \n",
       "17 0.169000  0.371000  \n",
       "18 0.033000 -0.010000  \n",
       "19 0.581987  0.799517  \n",
       "20       NO        NO  \n",
       "21       18        18  \n",
       "22       23        23  \n",
       "23 0.000000  0.000000  \n",
       "24 0.000000  0.000000  \n",
       "25 0.000000  0.000000  \n",
       "26      NaN       NaN  \n",
       "27       NO        NO  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6820d847-8c14-45d4-b9ce-4965ed7cf3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to round numerical columns to 3 decimal places\n",
    "def round_numeric_columns(df, decimals=3):\n",
    "    return df.applymap(lambda x: round(x, decimals) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Apply the rounding function to each DataFrame\n",
    "table1_df_global = round_numeric_columns(table1_df_global)\n",
    "table2_df_global = round_numeric_columns(table2_df_global)\n",
    "table3_df_global = round_numeric_columns(table3_df_global)\n",
    "table4_df_global = round_numeric_columns(table4_df_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2deaacaf-5b7b-4d65-9cca-84ab6b1eb003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attributes</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>N*</th>\n",
       "      <th>Mean</th>\n",
       "      <th>StDev</th>\n",
       "      <th>Minimum</th>\n",
       "      <th>Median</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>107.776</td>\n",
       "      <td>4.468</td>\n",
       "      <td>98.580</td>\n",
       "      <td>107.380</td>\n",
       "      <td>123.210</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Comps</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>103.087</td>\n",
       "      <td>3.754</td>\n",
       "      <td>90.350</td>\n",
       "      <td>103.315</td>\n",
       "      <td>110.640</td>\n",
       "      <td>-0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>104.908</td>\n",
       "      <td>6.349</td>\n",
       "      <td>90.600</td>\n",
       "      <td>103.770</td>\n",
       "      <td>122.070</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Comps_Thick</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>101.942</td>\n",
       "      <td>7.876</td>\n",
       "      <td>81.960</td>\n",
       "      <td>102.790</td>\n",
       "      <td>115.890</td>\n",
       "      <td>-0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 High Density Cgf-Cgf</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>Comps_Thin</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>107.266</td>\n",
       "      <td>7.881</td>\n",
       "      <td>88.610</td>\n",
       "      <td>107.435</td>\n",
       "      <td>125.840</td>\n",
       "      <td>-0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>Kfactor_Init-1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>L_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>EVONIK</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Q Taper Blk-Blk</td>\n",
       "      <td>SILSTAB</td>\n",
       "      <td>W_Shrink</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Attributes    GROUP        Variable   N  N*     Mean  StDev  \\\n",
       "0   0.5 High Density Cgf-Cgf   EVONIK           Comps  64   0  107.776  4.468   \n",
       "1   0.5 High Density Cgf-Cgf  SILSTAB           Comps  38   0  103.087  3.754   \n",
       "2   0.5 High Density Cgf-Cgf   EVONIK     Comps_Thick  64   0  104.908  6.349   \n",
       "3   0.5 High Density Cgf-Cgf  SILSTAB     Comps_Thick  38   0  101.942  7.876   \n",
       "4   0.5 High Density Cgf-Cgf   EVONIK      Comps_Thin  64   0  107.266  7.881   \n",
       "..                       ...      ...             ...  ..  ..      ...    ...   \n",
       "75           Q Taper Blk-Blk  SILSTAB  Kfactor_Init-1  18   0    0.000  0.000   \n",
       "76           Q Taper Blk-Blk   EVONIK        L_Shrink  23   0    0.000  0.000   \n",
       "77           Q Taper Blk-Blk  SILSTAB        L_Shrink  18   0    0.000  0.000   \n",
       "78           Q Taper Blk-Blk   EVONIK        W_Shrink  23   0    0.000  0.000   \n",
       "79           Q Taper Blk-Blk  SILSTAB        W_Shrink  18   0    0.000  0.000   \n",
       "\n",
       "   Minimum   Median  Maximum Skewness  \n",
       "0   98.580  107.380  123.210    0.679  \n",
       "1   90.350  103.315  110.640   -0.915  \n",
       "2   90.600  103.770  122.070    0.414  \n",
       "3   81.960  102.790  115.890   -0.450  \n",
       "4   88.610  107.435  125.840   -0.098  \n",
       "..     ...      ...      ...      ...  \n",
       "75   0.000    0.000    0.000    0.000  \n",
       "76   0.000    0.000    0.000    0.000  \n",
       "77   0.000    0.000    0.000    0.000  \n",
       "78   0.000    0.000    0.000    0.000  \n",
       "79   0.000    0.000    0.000    0.000  \n",
       "\n",
       "[80 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3a30e74-0bf6-4c08-808f-eb151ab124c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from PIL import Image\n",
    "from openpyxl import load_workbook, Workbook\n",
    "from openpyxl.drawing.image import Image as OpenpyxlImage\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side\n",
    "\n",
    "# Assuming table1_df_global, table2_df_global, table3_df_global, and table4_df_global are already defined\n",
    "\n",
    "# Define the output path for the Excel file\n",
    "output_path = 'test_trial_final_6.xlsx'\n",
    "\n",
    "# Function to apply styles to a range of cells\n",
    "def style_range(ws, cell_range, font=None, fill=None, border=None):\n",
    "    rows = ws[cell_range]\n",
    "    for row in rows:\n",
    "        for cell in row:\n",
    "            if font:\n",
    "                cell.font = font\n",
    "            if fill:\n",
    "                cell.fill = fill\n",
    "            if border:\n",
    "                cell.border = border\n",
    "\n",
    "# Function to write and style a DataFrame in the Excel sheet\n",
    "def write_dataframe_to_excel(sheet, df, start_row, header_font, header_fill, thin_border):\n",
    "    # Write the headers\n",
    "    for col_num, col_name in enumerate(df.columns, start=1):\n",
    "        cell = sheet.cell(row=start_row, column=col_num, value=col_name)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.border = thin_border\n",
    "\n",
    "    # Apply the header style\n",
    "    style_range(sheet, f'A{start_row}:{chr(64 + len(df.columns))}{start_row}', font=header_font, fill=header_fill, border=thin_border)\n",
    "    \n",
    "    start_row += 1\n",
    "\n",
    "    # Write the data\n",
    "    for row_num, r in enumerate(df.itertuples(index=False), start=start_row):\n",
    "        for col_num, value in enumerate(r, start=1):\n",
    "            # Convert lists and dictionaries to strings\n",
    "            if isinstance(value, list):\n",
    "                value = ', '.join(map(str, value))\n",
    "            elif isinstance(value, dict):\n",
    "                value = ', '.join(f'{k}: {v}' for k, v in value.items())\n",
    "            cell = sheet.cell(row=row_num, column=col_num, value=value)\n",
    "            cell.border = thin_border\n",
    "\n",
    "    # Update the start_row for the next DataFrame\n",
    "    return row_num + 5  # Leave 5 empty rows between tables\n",
    "\n",
    "# Create a new Excel file and write the first DataFrame to it using openpyxl\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    table1_df_global.to_excel(writer, sheet_name='tables', startrow=0, index=False)\n",
    "\n",
    "# Load the workbook and the worksheet with openpyxl for further modifications\n",
    "book = load_workbook(output_path)\n",
    "sheet = book['tables']\n",
    "\n",
    "# Define styles\n",
    "header_font = Font(bold=True)\n",
    "header_fill = PatternFill(start_color=\"D3D3D3\", end_color=\"D3D3D3\", fill_type=\"solid\")\n",
    "thin_border = Border(left=Side(style='thin'),\n",
    "                     right=Side(style='thin'),\n",
    "                     top=Side(style='thin'),\n",
    "                     bottom=Side(style='thin'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2eac19-e883-495a-b8ff-422cc2d900a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
